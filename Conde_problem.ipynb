{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Conde_problem.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "uBZxLYAvMUdj"
      },
      "source": [
        "import numpy as np\r\n",
        "import pandas as pd\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "from mlxtend.preprocessing import minmax_scaling \r\n",
        "import tensorflow as tf\r\n",
        "import io\r\n",
        "import plotly.graph_objs as go\r\n",
        "import plotly.offline as py\r\n",
        "import plotly.express as px"
      ],
      "execution_count": 101,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L-Jv6qWBMk4y",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "a673b1ff-f98d-4c22-9c1f-56f6f7b96734"
      },
      "source": [
        "#upload train and test files\r\n",
        "'''from google.colab import files\r\n",
        "uploaded = files.upload()'''"
      ],
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'from google.colab import files\\nuploaded = files.upload()'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 102
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mF5_svNKOU1R"
      },
      "source": [
        "#data loaded here\r\n",
        "ori_data = pd.read_csv(io.BytesIO(uploaded['train.csv']))"
      ],
      "execution_count": 103,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 820
        },
        "id": "mgekLZ9ZPCcL",
        "outputId": "0afc3ac3-dc1e-4dac-e80e-0cbfc727f9d0"
      },
      "source": [
        "display(ori_data.info(),ori_data.head())"
      ],
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 27000 entries, 0 to 26999\n",
            "Data columns (total 25 columns):\n",
            " #   Column                      Non-Null Count  Dtype\n",
            "---  ------                      --------------  -----\n",
            " 0   ID                          27000 non-null  int64\n",
            " 1   LIMIT_BAL                   27000 non-null  int64\n",
            " 2   SEX                         27000 non-null  int64\n",
            " 3   EDUCATION                   27000 non-null  int64\n",
            " 4   MARRIAGE                    27000 non-null  int64\n",
            " 5   AGE                         27000 non-null  int64\n",
            " 6   PAY_0                       27000 non-null  int64\n",
            " 7   PAY_2                       27000 non-null  int64\n",
            " 8   PAY_3                       27000 non-null  int64\n",
            " 9   PAY_4                       27000 non-null  int64\n",
            " 10  PAY_5                       27000 non-null  int64\n",
            " 11  PAY_6                       27000 non-null  int64\n",
            " 12  BILL_AMT1                   27000 non-null  int64\n",
            " 13  BILL_AMT2                   27000 non-null  int64\n",
            " 14  BILL_AMT3                   27000 non-null  int64\n",
            " 15  BILL_AMT4                   27000 non-null  int64\n",
            " 16  BILL_AMT5                   27000 non-null  int64\n",
            " 17  BILL_AMT6                   27000 non-null  int64\n",
            " 18  PAY_AMT1                    27000 non-null  int64\n",
            " 19  PAY_AMT2                    27000 non-null  int64\n",
            " 20  PAY_AMT3                    27000 non-null  int64\n",
            " 21  PAY_AMT4                    27000 non-null  int64\n",
            " 22  PAY_AMT5                    27000 non-null  int64\n",
            " 23  PAY_AMT6                    27000 non-null  int64\n",
            " 24  default payment next month  27000 non-null  int64\n",
            "dtypes: int64(25)\n",
            "memory usage: 5.1 MB\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "None"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ID</th>\n",
              "      <th>LIMIT_BAL</th>\n",
              "      <th>SEX</th>\n",
              "      <th>EDUCATION</th>\n",
              "      <th>MARRIAGE</th>\n",
              "      <th>AGE</th>\n",
              "      <th>PAY_0</th>\n",
              "      <th>PAY_2</th>\n",
              "      <th>PAY_3</th>\n",
              "      <th>PAY_4</th>\n",
              "      <th>PAY_5</th>\n",
              "      <th>PAY_6</th>\n",
              "      <th>BILL_AMT1</th>\n",
              "      <th>BILL_AMT2</th>\n",
              "      <th>BILL_AMT3</th>\n",
              "      <th>BILL_AMT4</th>\n",
              "      <th>BILL_AMT5</th>\n",
              "      <th>BILL_AMT6</th>\n",
              "      <th>PAY_AMT1</th>\n",
              "      <th>PAY_AMT2</th>\n",
              "      <th>PAY_AMT3</th>\n",
              "      <th>PAY_AMT4</th>\n",
              "      <th>PAY_AMT5</th>\n",
              "      <th>PAY_AMT6</th>\n",
              "      <th>default payment next month</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>13523</td>\n",
              "      <td>160000</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>36</td>\n",
              "      <td>-2</td>\n",
              "      <td>-2</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>2992</td>\n",
              "      <td>1300</td>\n",
              "      <td>8899</td>\n",
              "      <td>6257</td>\n",
              "      <td>-1197</td>\n",
              "      <td>12151</td>\n",
              "      <td>1300</td>\n",
              "      <td>12038</td>\n",
              "      <td>10696</td>\n",
              "      <td>613</td>\n",
              "      <td>14262</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>20458</td>\n",
              "      <td>100000</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>25</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>1522</td>\n",
              "      <td>291</td>\n",
              "      <td>1791</td>\n",
              "      <td>2367</td>\n",
              "      <td>4589</td>\n",
              "      <td>291</td>\n",
              "      <td>291</td>\n",
              "      <td>1791</td>\n",
              "      <td>2367</td>\n",
              "      <td>4613</td>\n",
              "      <td>291</td>\n",
              "      <td>291</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5538</td>\n",
              "      <td>150000</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>29</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>46625</td>\n",
              "      <td>66174</td>\n",
              "      <td>81085</td>\n",
              "      <td>75300</td>\n",
              "      <td>77276</td>\n",
              "      <td>64065</td>\n",
              "      <td>30151</td>\n",
              "      <td>40104</td>\n",
              "      <td>10013</td>\n",
              "      <td>5083</td>\n",
              "      <td>1819</td>\n",
              "      <td>4793</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>29048</td>\n",
              "      <td>120000</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>65</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>58436</td>\n",
              "      <td>60202</td>\n",
              "      <td>61042</td>\n",
              "      <td>61253</td>\n",
              "      <td>57695</td>\n",
              "      <td>2530</td>\n",
              "      <td>2740</td>\n",
              "      <td>2407</td>\n",
              "      <td>1421</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>840</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>10181</td>\n",
              "      <td>40000</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>25</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>25741</td>\n",
              "      <td>26772</td>\n",
              "      <td>27794</td>\n",
              "      <td>29333</td>\n",
              "      <td>29816</td>\n",
              "      <td>30577</td>\n",
              "      <td>1750</td>\n",
              "      <td>1772</td>\n",
              "      <td>2311</td>\n",
              "      <td>1100</td>\n",
              "      <td>1400</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      ID  LIMIT_BAL  SEX  ...  PAY_AMT5  PAY_AMT6  default payment next month\n",
              "0  13523     160000    2  ...     14262         0                           0\n",
              "1  20458     100000    1  ...       291       291                           0\n",
              "2   5538     150000    1  ...      1819      4793                           0\n",
              "3  29048     120000    2  ...         0       840                           0\n",
              "4  10181      40000    2  ...      1400         0                           1\n",
              "\n",
              "[5 rows x 25 columns]"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QDjh5EFXP-3Q",
        "outputId": "7b50b5a5-6e83-496a-8858-858c8d4a33b1"
      },
      "source": [
        "ori_data['SEX'].unique()"
      ],
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([2, 1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 105
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Lod1xW2QMep",
        "outputId": "4bb9277b-4bcd-4a25-d431-f469e1d0c856"
      },
      "source": [
        "ori_data['EDUCATION'].unique()"
      ],
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([2, 1, 3, 5, 6, 4, 0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 106
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 354
        },
        "id": "BbvggbgiQ0s4",
        "outputId": "4ee8d88f-0423-49ba-b31d-c9feeafe4db8"
      },
      "source": [
        "ori_data.groupby(['EDUCATION']).count().max(level=0)"
      ],
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ID</th>\n",
              "      <th>LIMIT_BAL</th>\n",
              "      <th>SEX</th>\n",
              "      <th>MARRIAGE</th>\n",
              "      <th>AGE</th>\n",
              "      <th>PAY_0</th>\n",
              "      <th>PAY_2</th>\n",
              "      <th>PAY_3</th>\n",
              "      <th>PAY_4</th>\n",
              "      <th>PAY_5</th>\n",
              "      <th>PAY_6</th>\n",
              "      <th>BILL_AMT1</th>\n",
              "      <th>BILL_AMT2</th>\n",
              "      <th>BILL_AMT3</th>\n",
              "      <th>BILL_AMT4</th>\n",
              "      <th>BILL_AMT5</th>\n",
              "      <th>BILL_AMT6</th>\n",
              "      <th>PAY_AMT1</th>\n",
              "      <th>PAY_AMT2</th>\n",
              "      <th>PAY_AMT3</th>\n",
              "      <th>PAY_AMT4</th>\n",
              "      <th>PAY_AMT5</th>\n",
              "      <th>PAY_AMT6</th>\n",
              "      <th>default payment next month</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>EDUCATION</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>9510</td>\n",
              "      <td>9510</td>\n",
              "      <td>9510</td>\n",
              "      <td>9510</td>\n",
              "      <td>9510</td>\n",
              "      <td>9510</td>\n",
              "      <td>9510</td>\n",
              "      <td>9510</td>\n",
              "      <td>9510</td>\n",
              "      <td>9510</td>\n",
              "      <td>9510</td>\n",
              "      <td>9510</td>\n",
              "      <td>9510</td>\n",
              "      <td>9510</td>\n",
              "      <td>9510</td>\n",
              "      <td>9510</td>\n",
              "      <td>9510</td>\n",
              "      <td>9510</td>\n",
              "      <td>9510</td>\n",
              "      <td>9510</td>\n",
              "      <td>9510</td>\n",
              "      <td>9510</td>\n",
              "      <td>9510</td>\n",
              "      <td>9510</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>12662</td>\n",
              "      <td>12662</td>\n",
              "      <td>12662</td>\n",
              "      <td>12662</td>\n",
              "      <td>12662</td>\n",
              "      <td>12662</td>\n",
              "      <td>12662</td>\n",
              "      <td>12662</td>\n",
              "      <td>12662</td>\n",
              "      <td>12662</td>\n",
              "      <td>12662</td>\n",
              "      <td>12662</td>\n",
              "      <td>12662</td>\n",
              "      <td>12662</td>\n",
              "      <td>12662</td>\n",
              "      <td>12662</td>\n",
              "      <td>12662</td>\n",
              "      <td>12662</td>\n",
              "      <td>12662</td>\n",
              "      <td>12662</td>\n",
              "      <td>12662</td>\n",
              "      <td>12662</td>\n",
              "      <td>12662</td>\n",
              "      <td>12662</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4410</td>\n",
              "      <td>4410</td>\n",
              "      <td>4410</td>\n",
              "      <td>4410</td>\n",
              "      <td>4410</td>\n",
              "      <td>4410</td>\n",
              "      <td>4410</td>\n",
              "      <td>4410</td>\n",
              "      <td>4410</td>\n",
              "      <td>4410</td>\n",
              "      <td>4410</td>\n",
              "      <td>4410</td>\n",
              "      <td>4410</td>\n",
              "      <td>4410</td>\n",
              "      <td>4410</td>\n",
              "      <td>4410</td>\n",
              "      <td>4410</td>\n",
              "      <td>4410</td>\n",
              "      <td>4410</td>\n",
              "      <td>4410</td>\n",
              "      <td>4410</td>\n",
              "      <td>4410</td>\n",
              "      <td>4410</td>\n",
              "      <td>4410</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>111</td>\n",
              "      <td>111</td>\n",
              "      <td>111</td>\n",
              "      <td>111</td>\n",
              "      <td>111</td>\n",
              "      <td>111</td>\n",
              "      <td>111</td>\n",
              "      <td>111</td>\n",
              "      <td>111</td>\n",
              "      <td>111</td>\n",
              "      <td>111</td>\n",
              "      <td>111</td>\n",
              "      <td>111</td>\n",
              "      <td>111</td>\n",
              "      <td>111</td>\n",
              "      <td>111</td>\n",
              "      <td>111</td>\n",
              "      <td>111</td>\n",
              "      <td>111</td>\n",
              "      <td>111</td>\n",
              "      <td>111</td>\n",
              "      <td>111</td>\n",
              "      <td>111</td>\n",
              "      <td>111</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>250</td>\n",
              "      <td>250</td>\n",
              "      <td>250</td>\n",
              "      <td>250</td>\n",
              "      <td>250</td>\n",
              "      <td>250</td>\n",
              "      <td>250</td>\n",
              "      <td>250</td>\n",
              "      <td>250</td>\n",
              "      <td>250</td>\n",
              "      <td>250</td>\n",
              "      <td>250</td>\n",
              "      <td>250</td>\n",
              "      <td>250</td>\n",
              "      <td>250</td>\n",
              "      <td>250</td>\n",
              "      <td>250</td>\n",
              "      <td>250</td>\n",
              "      <td>250</td>\n",
              "      <td>250</td>\n",
              "      <td>250</td>\n",
              "      <td>250</td>\n",
              "      <td>250</td>\n",
              "      <td>250</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>47</td>\n",
              "      <td>47</td>\n",
              "      <td>47</td>\n",
              "      <td>47</td>\n",
              "      <td>47</td>\n",
              "      <td>47</td>\n",
              "      <td>47</td>\n",
              "      <td>47</td>\n",
              "      <td>47</td>\n",
              "      <td>47</td>\n",
              "      <td>47</td>\n",
              "      <td>47</td>\n",
              "      <td>47</td>\n",
              "      <td>47</td>\n",
              "      <td>47</td>\n",
              "      <td>47</td>\n",
              "      <td>47</td>\n",
              "      <td>47</td>\n",
              "      <td>47</td>\n",
              "      <td>47</td>\n",
              "      <td>47</td>\n",
              "      <td>47</td>\n",
              "      <td>47</td>\n",
              "      <td>47</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "              ID  LIMIT_BAL  ...  PAY_AMT6  default payment next month\n",
              "EDUCATION                    ...                                      \n",
              "0             10         10  ...        10                          10\n",
              "1           9510       9510  ...      9510                        9510\n",
              "2          12662      12662  ...     12662                       12662\n",
              "3           4410       4410  ...      4410                        4410\n",
              "4            111        111  ...       111                         111\n",
              "5            250        250  ...       250                         250\n",
              "6             47         47  ...        47                          47\n",
              "\n",
              "[7 rows x 24 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 107
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vNnytIGKRPsZ"
      },
      "source": [
        "ori_data.loc[(ori_data['EDUCATION'] == 0), 'EDUCATION'] = 2"
      ],
      "execution_count": 108,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b7XFmbahRzVR",
        "outputId": "ef24716b-8178-4ac0-bc65-23cb0f1950a1"
      },
      "source": [
        "ori_data['EDUCATION'].unique()"
      ],
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([2, 1, 3, 5, 6, 4])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 109
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SFPx6n7ZR4B_",
        "outputId": "5f2eaa5d-09d7-4dc1-d473-b3fb317e581d"
      },
      "source": [
        "ori_data['MARRIAGE'].unique()"
      ],
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([2, 1, 3, 0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 110
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 266
        },
        "id": "RNu9N-MwSPbP",
        "outputId": "f27b57ad-d216-4900-a29c-ff07d5847ea3"
      },
      "source": [
        "ori_data.groupby(['MARRIAGE']).count().max(level=0)"
      ],
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ID</th>\n",
              "      <th>LIMIT_BAL</th>\n",
              "      <th>SEX</th>\n",
              "      <th>EDUCATION</th>\n",
              "      <th>AGE</th>\n",
              "      <th>PAY_0</th>\n",
              "      <th>PAY_2</th>\n",
              "      <th>PAY_3</th>\n",
              "      <th>PAY_4</th>\n",
              "      <th>PAY_5</th>\n",
              "      <th>PAY_6</th>\n",
              "      <th>BILL_AMT1</th>\n",
              "      <th>BILL_AMT2</th>\n",
              "      <th>BILL_AMT3</th>\n",
              "      <th>BILL_AMT4</th>\n",
              "      <th>BILL_AMT5</th>\n",
              "      <th>BILL_AMT6</th>\n",
              "      <th>PAY_AMT1</th>\n",
              "      <th>PAY_AMT2</th>\n",
              "      <th>PAY_AMT3</th>\n",
              "      <th>PAY_AMT4</th>\n",
              "      <th>PAY_AMT5</th>\n",
              "      <th>PAY_AMT6</th>\n",
              "      <th>default payment next month</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>MARRIAGE</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>44</td>\n",
              "      <td>44</td>\n",
              "      <td>44</td>\n",
              "      <td>44</td>\n",
              "      <td>44</td>\n",
              "      <td>44</td>\n",
              "      <td>44</td>\n",
              "      <td>44</td>\n",
              "      <td>44</td>\n",
              "      <td>44</td>\n",
              "      <td>44</td>\n",
              "      <td>44</td>\n",
              "      <td>44</td>\n",
              "      <td>44</td>\n",
              "      <td>44</td>\n",
              "      <td>44</td>\n",
              "      <td>44</td>\n",
              "      <td>44</td>\n",
              "      <td>44</td>\n",
              "      <td>44</td>\n",
              "      <td>44</td>\n",
              "      <td>44</td>\n",
              "      <td>44</td>\n",
              "      <td>44</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>12281</td>\n",
              "      <td>12281</td>\n",
              "      <td>12281</td>\n",
              "      <td>12281</td>\n",
              "      <td>12281</td>\n",
              "      <td>12281</td>\n",
              "      <td>12281</td>\n",
              "      <td>12281</td>\n",
              "      <td>12281</td>\n",
              "      <td>12281</td>\n",
              "      <td>12281</td>\n",
              "      <td>12281</td>\n",
              "      <td>12281</td>\n",
              "      <td>12281</td>\n",
              "      <td>12281</td>\n",
              "      <td>12281</td>\n",
              "      <td>12281</td>\n",
              "      <td>12281</td>\n",
              "      <td>12281</td>\n",
              "      <td>12281</td>\n",
              "      <td>12281</td>\n",
              "      <td>12281</td>\n",
              "      <td>12281</td>\n",
              "      <td>12281</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>14390</td>\n",
              "      <td>14390</td>\n",
              "      <td>14390</td>\n",
              "      <td>14390</td>\n",
              "      <td>14390</td>\n",
              "      <td>14390</td>\n",
              "      <td>14390</td>\n",
              "      <td>14390</td>\n",
              "      <td>14390</td>\n",
              "      <td>14390</td>\n",
              "      <td>14390</td>\n",
              "      <td>14390</td>\n",
              "      <td>14390</td>\n",
              "      <td>14390</td>\n",
              "      <td>14390</td>\n",
              "      <td>14390</td>\n",
              "      <td>14390</td>\n",
              "      <td>14390</td>\n",
              "      <td>14390</td>\n",
              "      <td>14390</td>\n",
              "      <td>14390</td>\n",
              "      <td>14390</td>\n",
              "      <td>14390</td>\n",
              "      <td>14390</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>285</td>\n",
              "      <td>285</td>\n",
              "      <td>285</td>\n",
              "      <td>285</td>\n",
              "      <td>285</td>\n",
              "      <td>285</td>\n",
              "      <td>285</td>\n",
              "      <td>285</td>\n",
              "      <td>285</td>\n",
              "      <td>285</td>\n",
              "      <td>285</td>\n",
              "      <td>285</td>\n",
              "      <td>285</td>\n",
              "      <td>285</td>\n",
              "      <td>285</td>\n",
              "      <td>285</td>\n",
              "      <td>285</td>\n",
              "      <td>285</td>\n",
              "      <td>285</td>\n",
              "      <td>285</td>\n",
              "      <td>285</td>\n",
              "      <td>285</td>\n",
              "      <td>285</td>\n",
              "      <td>285</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             ID  LIMIT_BAL  ...  PAY_AMT6  default payment next month\n",
              "MARRIAGE                    ...                                      \n",
              "0            44         44  ...        44                          44\n",
              "1         12281      12281  ...     12281                       12281\n",
              "2         14390      14390  ...     14390                       14390\n",
              "3           285        285  ...       285                         285\n",
              "\n",
              "[4 rows x 24 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 111
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_lzhGEYLSZVB"
      },
      "source": [
        "ori_data.loc[(ori_data['MARRIAGE'] == 0), 'MARRIAGE'] = 2"
      ],
      "execution_count": 112,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-U4HxKy6Sfo_",
        "outputId": "79f5edd7-046e-422c-b0ee-3f48b7741caa"
      },
      "source": [
        "ori_data['MARRIAGE'].unique()"
      ],
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([2, 1, 3])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 113
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C7wutQdcSh7H",
        "outputId": "8fed7387-3168-429e-c206-54c0f9e1b22e"
      },
      "source": [
        "absurd_age = ori_data[ori_data['AGE']>=130 ]\r\n",
        "absurd_age.size"
      ],
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 114
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zu8z0TzuTrqp",
        "outputId": "dd2a2a52-8d58-4b1d-8d50-c55ec8b31db9"
      },
      "source": [
        "ori_data['PAY_0'].unique()"
      ],
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-2, -1,  0,  2,  1,  3,  4,  8,  5,  6,  7])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 115
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JpT0-t2VUfqe"
      },
      "source": [
        "ori_data.loc[(ori_data['PAY_0'] == -2) & ((ori_data['BILL_AMT1']-ori_data['PAY_AMT1'])<=0), 'PAY_0'] = -1"
      ],
      "execution_count": 116,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yqmk7dBmUsyw"
      },
      "source": [
        "ori_data.loc[(ori_data['PAY_0'] == -2) & (ori_data['PAY_2'] == -2) & ((ori_data['BILL_AMT2']-ori_data['PAY_AMT2'])<=0), ('PAY_0','PAY_2')] = (1,1)"
      ],
      "execution_count": 117,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O4qeVbSTaVww"
      },
      "source": [
        "ori_data.loc[(ori_data['PAY_0'] == -2) & (ori_data['PAY_2'] == -2) & (ori_data['PAY_3'] == -2) & ((ori_data['BILL_AMT3']-ori_data['PAY_AMT3'])<=0), ('PAY_0','PAY_2','PAY_3')] = (2,2,2)"
      ],
      "execution_count": 118,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HXnkZFb4ak7e"
      },
      "source": [
        "ori_data.loc[(ori_data['PAY_0'] == -2) & (ori_data['PAY_2'] == -2) & (ori_data['PAY_3'] == -2) & (ori_data['PAY_4'] == -2) & ((ori_data['BILL_AMT4']-ori_data['PAY_AMT4'])<=0), ('PAY_0','PAY_2','PAY_3','PAY_4')] = (3,3,3,3)"
      ],
      "execution_count": 119,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dYjx29nNa1l-"
      },
      "source": [
        "ori_data.loc[(ori_data['PAY_0'] == -2) & (ori_data['PAY_2'] == -2) & (ori_data['PAY_3'] == -2) & (ori_data['PAY_4'] == -2) & (ori_data['PAY_5'] == -2) & ((ori_data['BILL_AMT5']-ori_data['PAY_AMT5'])<=0), ('PAY_0','PAY_2','PAY_3','PAY_4','PAY_5')] = (4,4,4,4,4)"
      ],
      "execution_count": 120,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9-R0N8kGbQYN"
      },
      "source": [
        "ori_data.loc[(ori_data['PAY_0'] == -2) & (ori_data['PAY_2'] == -2) & (ori_data['PAY_3'] == -2) & (ori_data['PAY_4'] == -2) & (ori_data['PAY_5'] == -2) & (ori_data['PAY_6'] == -2) & ((ori_data['BILL_AMT6']-ori_data['PAY_AMT6'])<=0), ('PAY_0','PAY_2','PAY_3','PAY_4','PAY_5','PAY_6')] = (5,5,5,5,5,5)"
      ],
      "execution_count": 121,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uArZrHrnbxrf"
      },
      "source": [
        "ori_data.loc[(ori_data['PAY_0'] == -2) & (ori_data['PAY_2'] == -2) & (ori_data['PAY_3'] == -2) & (ori_data['PAY_4'] == -2) & (ori_data['PAY_5'] == -2) & (ori_data['PAY_6'] == -2) & ((ori_data['BILL_AMT6']-ori_data['PAY_AMT6'])>0), ('PAY_0','PAY_2','PAY_3','PAY_4','PAY_5','PAY_6')] = (6,6,6,6,6,6)"
      ],
      "execution_count": 123,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 454
        },
        "id": "i528a2vXcxde",
        "outputId": "b222f379-689b-4a56-e7f1-6aac1d48cf22"
      },
      "source": [
        "display(ori_data.isnull().sum())"
      ],
      "execution_count": 124,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "ID                            0\n",
              "LIMIT_BAL                     0\n",
              "SEX                           0\n",
              "EDUCATION                     0\n",
              "MARRIAGE                      0\n",
              "AGE                           0\n",
              "PAY_0                         0\n",
              "PAY_2                         0\n",
              "PAY_3                         0\n",
              "PAY_4                         0\n",
              "PAY_5                         0\n",
              "PAY_6                         0\n",
              "BILL_AMT1                     0\n",
              "BILL_AMT2                     0\n",
              "BILL_AMT3                     0\n",
              "BILL_AMT4                     0\n",
              "BILL_AMT5                     0\n",
              "BILL_AMT6                     0\n",
              "PAY_AMT1                      0\n",
              "PAY_AMT2                      0\n",
              "PAY_AMT3                      0\n",
              "PAY_AMT4                      0\n",
              "PAY_AMT5                      0\n",
              "PAY_AMT6                      0\n",
              "default payment next month    0\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "XkNCuPDoclRv",
        "outputId": "9b01d180-b613-4527-d9d7-ca2e185fe344"
      },
      "source": [
        "def correlation_plot():\r\n",
        "    #correlation\r\n",
        "    correlation = ori_data.corr()\r\n",
        "    #tick labels\r\n",
        "    matrix_cols = correlation.columns.tolist()\r\n",
        "    #convert to array\r\n",
        "    corr_array  = np.array(correlation)\r\n",
        "    trace = go.Heatmap(z = corr_array,\r\n",
        "                       x = matrix_cols,\r\n",
        "                       y = matrix_cols,\r\n",
        "                       colorscale='Viridis',\r\n",
        "                       colorbar   = dict() \r\n",
        "                      )\r\n",
        "    layout = go.Layout(dict(title = 'Correlation Matrix for variables',\r\n",
        "                            #autosize = False,\r\n",
        "                            #height  = 1400,\r\n",
        "                            #width   = 1600,\r\n",
        "                            margin  = dict(r = 0 ,l = 100,\r\n",
        "                                           t = 0,b = 100,\r\n",
        "                                         ),\r\n",
        "                            yaxis   = dict(tickfont = dict(size = 9)),\r\n",
        "                            xaxis   = dict(tickfont = dict(size = 9)),\r\n",
        "                           )\r\n",
        "                      )\r\n",
        "    fig = go.Figure(data = [trace],layout = layout)\r\n",
        "    py.iplot(fig)\r\n",
        "correlation_plot()"
      ],
      "execution_count": 127,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>\n",
              "            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>\n",
              "                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-latest.min.js\"></script>    \n",
              "            <div id=\"2653715c-1178-496f-98ae-0963e5f52ad8\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>\n",
              "            <script type=\"text/javascript\">\n",
              "                \n",
              "                    window.PLOTLYENV=window.PLOTLYENV || {};\n",
              "                    \n",
              "                if (document.getElementById(\"2653715c-1178-496f-98ae-0963e5f52ad8\")) {\n",
              "                    Plotly.newPlot(\n",
              "                        '2653715c-1178-496f-98ae-0963e5f52ad8',\n",
              "                        [{\"colorscale\": [[0.0, \"#440154\"], [0.1111111111111111, \"#482878\"], [0.2222222222222222, \"#3e4989\"], [0.3333333333333333, \"#31688e\"], [0.4444444444444444, \"#26828e\"], [0.5555555555555556, \"#1f9e89\"], [0.6666666666666666, \"#35b779\"], [0.7777777777777778, \"#6ece58\"], [0.8888888888888888, \"#b5de2b\"], [1.0, \"#fde725\"]], \"type\": \"heatmap\", \"x\": [\"ID\", \"LIMIT_BAL\", \"SEX\", \"EDUCATION\", \"MARRIAGE\", \"AGE\", \"PAY_0\", \"PAY_2\", \"PAY_3\", \"PAY_4\", \"PAY_5\", \"PAY_6\", \"BILL_AMT1\", \"BILL_AMT2\", \"BILL_AMT3\", \"BILL_AMT4\", \"BILL_AMT5\", \"BILL_AMT6\", \"PAY_AMT1\", \"PAY_AMT2\", \"PAY_AMT3\", \"PAY_AMT4\", \"PAY_AMT5\", \"PAY_AMT6\", \"default payment next month\"], \"y\": [\"ID\", \"LIMIT_BAL\", \"SEX\", \"EDUCATION\", \"MARRIAGE\", \"AGE\", \"PAY_0\", \"PAY_2\", \"PAY_3\", \"PAY_4\", \"PAY_5\", \"PAY_6\", \"BILL_AMT1\", \"BILL_AMT2\", \"BILL_AMT3\", \"BILL_AMT4\", \"BILL_AMT5\", \"BILL_AMT6\", \"PAY_AMT1\", \"PAY_AMT2\", \"PAY_AMT3\", \"PAY_AMT4\", \"PAY_AMT5\", \"PAY_AMT6\", \"default payment next month\"], \"z\": [[1.0, 0.0288321646107744, 0.021657196932510458, 0.03926453631349122, -0.02598312598521418, 0.01766765079252358, -0.01187011864900887, -0.0017323912156080401, -0.01801204984128222, -0.006596918762472156, -0.027013181491425318, -0.022394493099782344, 0.02367878874815857, 0.022073688867200347, 0.027981224768089175, 0.04462230909816959, 0.02137947156321322, 0.021463542237021387, 0.01143723777396422, 0.008632819880421782, 0.04196907181639438, 0.009342018720378839, 0.0002981150473974802, 0.0070247905456763925, -0.01680193524973734], [0.0288321646107744, 1.0, 0.02693329391168705, -0.21619819954658326, -0.11002898536839846, 0.14394776121910133, -0.18662593643762077, -0.2322890160715037, -0.2555549778212127, -0.25575695598751996, -0.24367395130882882, -0.23250602797407546, 0.28617983722769974, 0.27955980982240564, 0.2846559826314324, 0.29450139997022695, 0.2958333870871192, 0.2912856131016214, 0.19687468815617912, 0.17690128336045616, 0.2118637133376424, 0.20195913813158772, 0.21971080270468393, 0.2169883947039238, -0.15227136334338004], [0.021657196932510458, 0.02693329391168705, 1.0, 0.014438641940627774, -0.02905950675729822, -0.08892665851707054, -0.04032420619504, -0.05850390463856485, -0.06310891939714013, -0.0582737847787853, -0.05097438606562827, -0.04098556989073762, -0.030222044946592738, -0.02752133112724039, -0.020270212024382058, -0.01839422257093177, -0.015235359724826992, -0.01526577693426262, 2.8636116728743145e-05, 0.0007723408030568177, -0.0070216402370346645, -0.004828766504527566, -0.002473976588884736, -0.001753168914684147, -0.04324693156510792], [0.03926453631349122, -0.21619819954658326, 0.014438641940627774, 1.0, -0.137489303978524, 0.17702579389886205, 0.08059252789605877, 0.0988636350358469, 0.10248362600352401, 0.1013541907979814, 0.09199395081363, 0.07707608009813002, 0.02486830890864582, 0.019332187438822247, 0.014447087939413175, 0.0005209857838140578, -0.0067731217938703184, -0.009428525927314073, -0.03834545862140401, -0.030106413398742673, -0.03966561212823331, -0.0394151544380619, -0.04560238322848675, -0.037016210816732134, 0.026672460225202775], [-0.02598312598521418, -0.11002898536839846, -0.02905950675729822, -0.137489303978524, 1.0, -0.41891678189249754, 0.0014500982334790641, 0.01264448146901082, 0.030476110808054326, 0.03262877336027905, 0.035597159253954715, 0.032610281424145716, -0.02730372710982138, -0.024331627203930575, -0.02777898229886014, -0.026082126770486484, -0.028924539213339713, -0.025049139047049883, -0.004025277607365567, -0.008242020620505336, -0.0030733077635779495, -0.012645013663190183, -0.0007524025924736099, -0.0058608823961573435, -0.026881575300564904], [0.01766765079252358, 0.14394776121910133, -0.08892665851707054, 0.17702579389886205, -0.41891678189249754, 1.0, -0.01360328276738549, -0.03619973300373852, -0.045727039039140806, -0.0476218683504295, -0.05360369266163475, -0.04820674310819564, 0.055616711461076225, 0.0540094806613382, 0.05245754345483176, 0.04978358325202801, 0.04870236415249223, 0.046557117206510866, 0.027191626299172746, 0.01910911869174446, 0.025515885399791004, 0.02149141457097964, 0.020781453304248656, 0.015893923109842584, 0.014746099910572432], [-0.01187011864900887, -0.18662593643762077, -0.04032420619504, 0.08059252789605877, 0.0014500982334790641, -0.01360328276738549, 1.0, 0.6385530744782558, 0.4905035627845137, 0.4279375808548815, 0.38142736331423654, 0.3437956367917696, 0.1273825238833423, 0.12020588300845984, 0.11456230091227425, 0.11482542062997979, 0.12032139553365924, 0.11821830182668623, -0.09187720737136279, -0.06263761521794124, -0.06715578081470114, -0.04577720352856779, -0.043423556460081704, -0.046388007074486794, 0.316533914788932], [-0.0017323912156080401, -0.2322890160715037, -0.05850390463856485, 0.0988636350358469, 0.01264448146901082, -0.03619973300373852, 0.6385530744782558, 1.0, 0.7114042757611964, 0.5829982691310925, 0.5295614333262039, 0.47960343480983963, 0.19775320241788255, 0.18629821685737938, 0.17745710636337675, 0.1762651160708956, 0.17755301930345313, 0.17696518472108647, -0.09192875473668774, -0.05222533507830281, -0.04936051811141728, -0.027959766815929966, -0.021016709530750927, -0.024446198477182154, 0.23543741201698137], [-0.01801204984128222, -0.2555549778212127, -0.06310891939714013, 0.10248362600352401, 0.030476110808054326, -0.045727039039140806, 0.4905035627845137, 0.7114042757611964, 1.0, 0.7529018074106977, 0.6496352181333238, 0.5893744584351148, 0.19698634963069075, 0.21870389778343557, 0.20535949627969918, 0.20454768818407873, 0.20430852169258873, 0.201309949223108, -0.0007158175306933499, -0.07009971158301559, -0.05160708804850212, -0.03298588169203206, -0.026900687095724213, -0.026109679108884003, 0.2194096950336221], [-0.006596918762472156, -0.25575695598751996, -0.0582737847787853, 0.1013541907979814, 0.03262877336027905, -0.0476218683504295, 0.4279375808548815, 0.5829982691310925, 0.7529018074106977, 1.0, 0.8101068077549922, 0.7031722201910511, 0.20062253179197265, 0.22045778177244083, 0.23663526343954822, 0.23424306638095385, 0.23214199253399995, 0.22822402014451373, -0.00921052480616276, -0.004919597841770236, -0.0703921833295093, -0.039048394575894124, -0.029303315686543676, -0.02127086385218039, 0.20873954961648547], [-0.027013181491425318, -0.24367395130882882, -0.05097438606562827, 0.09199395081363, 0.035597159253954715, -0.05360369266163475, 0.38142736331423654, 0.5295614333262039, 0.6496352181333238, 0.8101068077549922, 1.0, 0.8151856487441597, 0.2078065336080069, 0.22543071141739554, 0.239478388650546, 0.2657529463185514, 0.26292208084019675, 0.25502431454726804, -0.00787357208807166, -0.005215042031000779, 0.00717687130244074, -0.05812876638413849, -0.033869191230639376, -0.019757803216750427, 0.1977661240039747], [-0.022394493099782344, -0.23250602797407546, -0.04098556989073762, 0.07707608009813002, 0.032610281424145716, -0.04820674310819564, 0.3437956367917696, 0.47960343480983963, 0.5893744584351148, 0.7031722201910511, 0.8151856487441597, 1.0, 0.2073647786818114, 0.22517916269087662, 0.23766937571829447, 0.26145414292726454, 0.2852219560771475, 0.27873091453991505, -0.003244607021036683, -0.0063385232433003725, 0.0028198548239606797, 0.01745295321077273, -0.04734560520048222, -0.023761975767024775, 0.18389917596425873], [0.02367878874815857, 0.28617983722769974, -0.030222044946592738, 0.02486830890864582, -0.02730372710982138, 0.055616711461076225, 0.1273825238833423, 0.19775320241788255, 0.19698634963069075, 0.20062253179197265, 0.2078065336080069, 0.2073647786818114, 1.0, 0.9522010664576915, 0.8914858764030189, 0.861918802372521, 0.8301379435005662, 0.8033707104475167, 0.14442344045895136, 0.09434860080256192, 0.15547176728944306, 0.15779736232401262, 0.16976413369572596, 0.1769193769435828, -0.017343255625047568], [0.022073688867200347, 0.27955980982240564, -0.02752133112724039, 0.019332187438822247, -0.024331627203930575, 0.0540094806613382, 0.12020588300845984, 0.18629821685737938, 0.21870389778343557, 0.22045778177244083, 0.22543071141739554, 0.22517916269087662, 0.9522010664576915, 1.0, 0.9275325187043942, 0.8952091988987945, 0.8607182711286272, 0.8327849980316807, 0.2794553735992197, 0.09682301753900355, 0.1497689408038395, 0.14786285068450308, 0.16207036371531922, 0.17423777236053456, -0.012277657494008347], [0.027981224768089175, 0.2846559826314324, -0.020270212024382058, 0.014447087939413175, -0.02777898229886014, 0.05245754345483176, 0.11456230091227425, 0.17745710636337675, 0.20535949627969918, 0.23663526343954822, 0.239478388650546, 0.23766937571829447, 0.8914858764030189, 0.9275325187043942, 1.0, 0.9254255708419794, 0.8840907689146694, 0.8544395770302295, 0.2450992140441928, 0.31677332342860787, 0.1304639618078901, 0.14415005329832487, 0.1874747427356091, 0.18191596889459682, -0.012953252217398405], [0.04462230909816959, 0.29450139997022695, -0.01839422257093177, 0.0005209857838140578, -0.026082126770486484, 0.04978358325202801, 0.11482542062997979, 0.1762651160708956, 0.20454768818407873, 0.23424306638095385, 0.2657529463185514, 0.26145414292726454, 0.861918802372521, 0.8952091988987945, 0.9254255708419794, 1.0, 0.9405628098728989, 0.9016392901247916, 0.23851182206309943, 0.20205406627726782, 0.2967113102040293, 0.13105440762556067, 0.16483995999274728, 0.17547687220865424, -0.008080553181689548], [0.02137947156321322, 0.2958333870871192, -0.015235359724826992, -0.0067731217938703184, -0.028924539213339713, 0.04870236415249223, 0.12032139553365924, 0.17755301930345313, 0.20430852169258873, 0.23214199253399995, 0.26292208084019675, 0.2852219560771475, 0.8301379435005662, 0.8607182711286272, 0.8840907689146694, 0.9405628098728989, 1.0, 0.9466321552286937, 0.22243622021209766, 0.17498871354077683, 0.25477207579437927, 0.2915794283116845, 0.1445956154054825, 0.1605098586254459, -0.0054868727702786805], [0.021463542237021387, 0.2912856131016214, -0.01526577693426262, -0.009428525927314073, -0.025049139047049883, 0.046557117206510866, 0.11821830182668623, 0.17696518472108647, 0.201309949223108, 0.22822402014451373, 0.25502431454726804, 0.27873091453991505, 0.8033707104475167, 0.8327849980316807, 0.8544395770302295, 0.9016392901247916, 0.9466321552286937, 1.0, 0.20490034969917278, 0.16829130831774733, 0.23442296315772493, 0.25035732383886966, 0.3087471930981302, 0.11396504857935366, -0.004315193084973578], [0.01143723777396422, 0.19687468815617912, 2.8636116728743145e-05, -0.03834545862140401, -0.004025277607365567, 0.027191626299172746, -0.09187720737136279, -0.09192875473668774, -0.0007158175306933499, -0.00921052480616276, -0.00787357208807166, -0.003244607021036683, 0.14442344045895136, 0.2794553735992197, 0.2450992140441928, 0.23851182206309943, 0.22243622021209766, 0.20490034969917278, 1.0, 0.29535226555417315, 0.27119568662436844, 0.20915643941960477, 0.15296596294352696, 0.19131132743910528, -0.07276213799063401], [0.008632819880421782, 0.17690128336045616, 0.0007723408030568177, -0.030106413398742673, -0.008242020620505336, 0.01910911869174446, -0.06263761521794124, -0.05222533507830281, -0.07009971158301559, -0.004919597841770236, -0.005215042031000779, -0.0063385232433003725, 0.09434860080256192, 0.09682301753900355, 0.31677332342860787, 0.20205406627726782, 0.17498871354077683, 0.16829130831774733, 0.29535226555417315, 1.0, 0.2557403878508794, 0.18250990556898034, 0.1860825775366378, 0.15555000705722183, -0.057541188938266236], [0.04196907181639438, 0.2118637133376424, -0.0070216402370346645, -0.03966561212823331, -0.0030733077635779495, 0.025515885399791004, -0.06715578081470114, -0.04936051811141728, -0.05160708804850212, -0.0703921833295093, 0.00717687130244074, 0.0028198548239606797, 0.15547176728944306, 0.1497689408038395, 0.1304639618078901, 0.2967113102040293, 0.25477207579437927, 0.23442296315772493, 0.27119568662436844, 0.2557403878508794, 1.0, 0.22657401585362175, 0.1610463142926403, 0.1624465699529252, -0.055241359852804824], [0.009342018720378839, 0.20195913813158772, -0.004828766504527566, -0.0394151544380619, -0.012645013663190183, 0.02149141457097964, -0.04577720352856779, -0.027959766815929966, -0.03298588169203206, -0.039048394575894124, -0.05812876638413849, 0.01745295321077273, 0.15779736232401262, 0.14786285068450308, 0.14415005329832487, 0.13105440762556067, 0.2915794283116845, 0.25035732383886966, 0.20915643941960477, 0.18250990556898034, 0.22657401585362175, 1.0, 0.14584004107849238, 0.15442564381635152, -0.05708044744778961], [0.0002981150473974802, 0.21971080270468393, -0.002473976588884736, -0.04560238322848675, -0.0007524025924736099, 0.020781453304248656, -0.043423556460081704, -0.021016709530750927, -0.026900687095724213, -0.029303315686543676, -0.033869191230639376, -0.04734560520048222, 0.16976413369572596, 0.16207036371531922, 0.1874747427356091, 0.16483995999274728, 0.1445956154054825, 0.3087471930981302, 0.15296596294352696, 0.1860825775366378, 0.1610463142926403, 0.14584004107849238, 1.0, 0.1523888168145543, -0.05418944332162143], [0.0070247905456763925, 0.2169883947039238, -0.001753168914684147, -0.037016210816732134, -0.0058608823961573435, 0.015893923109842584, -0.046388007074486794, -0.024446198477182154, -0.026109679108884003, -0.02127086385218039, -0.019757803216750427, -0.023761975767024775, 0.1769193769435828, 0.17423777236053456, 0.18191596889459682, 0.17547687220865424, 0.1605098586254459, 0.11396504857935366, 0.19131132743910528, 0.15555000705722183, 0.1624465699529252, 0.15442564381635152, 0.1523888168145543, 1.0, -0.05265659257629406], [-0.01680193524973734, -0.15227136334338004, -0.04324693156510792, 0.026672460225202775, -0.026881575300564904, 0.014746099910572432, 0.316533914788932, 0.23543741201698137, 0.2194096950336221, 0.20873954961648547, 0.1977661240039747, 0.18389917596425873, -0.017343255625047568, -0.012277657494008347, -0.012953252217398405, -0.008080553181689548, -0.0054868727702786805, -0.004315193084973578, -0.07276213799063401, -0.057541188938266236, -0.055241359852804824, -0.05708044744778961, -0.05418944332162143, -0.05265659257629406, 1.0]]}],\n",
              "                        {\"margin\": {\"b\": 100, \"l\": 100, \"r\": 0, \"t\": 0}, \"template\": {\"data\": {\"bar\": [{\"error_x\": {\"color\": \"#2a3f5f\"}, \"error_y\": {\"color\": \"#2a3f5f\"}, \"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"bar\"}], \"barpolar\": [{\"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"barpolar\"}], \"carpet\": [{\"aaxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"baxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"type\": \"carpet\"}], \"choropleth\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"choropleth\"}], \"contour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"contour\"}], \"contourcarpet\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"contourcarpet\"}], \"heatmap\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmap\"}], \"heatmapgl\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmapgl\"}], \"histogram\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"histogram\"}], \"histogram2d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2d\"}], \"histogram2dcontour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2dcontour\"}], \"mesh3d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"mesh3d\"}], \"parcoords\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"parcoords\"}], \"pie\": [{\"automargin\": true, \"type\": \"pie\"}], \"scatter\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter\"}], \"scatter3d\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter3d\"}], \"scattercarpet\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattercarpet\"}], \"scattergeo\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergeo\"}], \"scattergl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergl\"}], \"scattermapbox\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattermapbox\"}], \"scatterpolar\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolar\"}], \"scatterpolargl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolargl\"}], \"scatterternary\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterternary\"}], \"surface\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"surface\"}], \"table\": [{\"cells\": {\"fill\": {\"color\": \"#EBF0F8\"}, \"line\": {\"color\": \"white\"}}, \"header\": {\"fill\": {\"color\": \"#C8D4E3\"}, \"line\": {\"color\": \"white\"}}, \"type\": \"table\"}]}, \"layout\": {\"annotationdefaults\": {\"arrowcolor\": \"#2a3f5f\", \"arrowhead\": 0, \"arrowwidth\": 1}, \"coloraxis\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"colorscale\": {\"diverging\": [[0, \"#8e0152\"], [0.1, \"#c51b7d\"], [0.2, \"#de77ae\"], [0.3, \"#f1b6da\"], [0.4, \"#fde0ef\"], [0.5, \"#f7f7f7\"], [0.6, \"#e6f5d0\"], [0.7, \"#b8e186\"], [0.8, \"#7fbc41\"], [0.9, \"#4d9221\"], [1, \"#276419\"]], \"sequential\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"sequentialminus\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]]}, \"colorway\": [\"#636efa\", \"#EF553B\", \"#00cc96\", \"#ab63fa\", \"#FFA15A\", \"#19d3f3\", \"#FF6692\", \"#B6E880\", \"#FF97FF\", \"#FECB52\"], \"font\": {\"color\": \"#2a3f5f\"}, \"geo\": {\"bgcolor\": \"white\", \"lakecolor\": \"white\", \"landcolor\": \"#E5ECF6\", \"showlakes\": true, \"showland\": true, \"subunitcolor\": \"white\"}, \"hoverlabel\": {\"align\": \"left\"}, \"hovermode\": \"closest\", \"mapbox\": {\"style\": \"light\"}, \"paper_bgcolor\": \"white\", \"plot_bgcolor\": \"#E5ECF6\", \"polar\": {\"angularaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"radialaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"scene\": {\"xaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"yaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"zaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}}, \"shapedefaults\": {\"line\": {\"color\": \"#2a3f5f\"}}, \"ternary\": {\"aaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"baxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"caxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"title\": {\"x\": 0.05}, \"xaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}, \"yaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}}}, \"title\": {\"text\": \"Correlation Matrix for variables\"}, \"xaxis\": {\"tickfont\": {\"size\": 9}}, \"yaxis\": {\"tickfont\": {\"size\": 9}}},\n",
              "                        {\"responsive\": true}\n",
              "                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('2653715c-1178-496f-98ae-0963e5f52ad8');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })\n",
              "                };\n",
              "                \n",
              "            </script>\n",
              "        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uWrL2zYFdll2"
      },
      "source": [
        "scaled_data = minmax_scaling(ori_data,columns=['ID','LIMIT_BAL',\r\n",
        "'SEX',\r\n",
        "'EDUCATION',\r\n",
        "'MARRIAGE',\r\n",
        "'AGE',\r\n",
        "'PAY_0',\r\n",
        "'PAY_2',\r\n",
        "'PAY_3',\r\n",
        "'PAY_4',\r\n",
        "'PAY_5',\r\n",
        "'PAY_6',\r\n",
        "'BILL_AMT1',\r\n",
        "'BILL_AMT2',\r\n",
        "'BILL_AMT3',\r\n",
        "'BILL_AMT4',\r\n",
        "'BILL_AMT5',\r\n",
        "'BILL_AMT6',\r\n",
        "'PAY_AMT1',\r\n",
        "'PAY_AMT2',\r\n",
        "'PAY_AMT3',\r\n",
        "'PAY_AMT4','PAY_AMT5','PAY_AMT6'])"
      ],
      "execution_count": 130,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VZapVo9Re0-Y"
      },
      "source": [
        "def build_model():\r\n",
        "    model = tf.keras.Sequential([tf.keras.layers.Dense(8, activation='relu', input_shape=[len(scaled_data.keys())]),\r\n",
        "                                tf.keras.layers.Dense(4, activation='relu'),\r\n",
        "                                tf.keras.layers.Dense(1,activation='sigmoid')\r\n",
        "                                ])\r\n",
        "\r\n",
        "    optimizer = tf.keras.optimizers.RMSprop(0.01)\r\n",
        "\r\n",
        "    model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\r\n",
        "    return model\r\n",
        "\r\n",
        "model = build_model()"
      ],
      "execution_count": 131,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jh8SV1_zfJQR",
        "outputId": "4b72e498-2dc8-40f1-f6b7-9eb23a6e7e86"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 132,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense (Dense)                (None, 8)                 200       \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 4)                 36        \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 1)                 5         \n",
            "=================================================================\n",
            "Total params: 241\n",
            "Trainable params: 241\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wz7Hix67fKz1",
        "outputId": "19e3998b-915a-4c5b-8bdd-fe900d4511df"
      },
      "source": [
        "EPOCHS = 500\r\n",
        "\r\n",
        "history = model.fit(scaled_data, ori_data['default payment next month'],epochs=EPOCHS, validation_split=0.2, verbose=2)"
      ],
      "execution_count": 135,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/500\n",
            "675/675 - 1s - loss: 0.4415 - accuracy: 0.8181 - val_loss: 0.4422 - val_accuracy: 0.8189\n",
            "Epoch 2/500\n",
            "675/675 - 1s - loss: 0.4410 - accuracy: 0.8177 - val_loss: 0.4438 - val_accuracy: 0.8180\n",
            "Epoch 3/500\n",
            "675/675 - 1s - loss: 0.4417 - accuracy: 0.8184 - val_loss: 0.4423 - val_accuracy: 0.8180\n",
            "Epoch 4/500\n",
            "675/675 - 1s - loss: 0.4402 - accuracy: 0.8172 - val_loss: 0.4486 - val_accuracy: 0.8170\n",
            "Epoch 5/500\n",
            "675/675 - 1s - loss: 0.4411 - accuracy: 0.8185 - val_loss: 0.4498 - val_accuracy: 0.8176\n",
            "Epoch 6/500\n",
            "675/675 - 1s - loss: 0.4407 - accuracy: 0.8186 - val_loss: 0.4424 - val_accuracy: 0.8183\n",
            "Epoch 7/500\n",
            "675/675 - 1s - loss: 0.4407 - accuracy: 0.8167 - val_loss: 0.4449 - val_accuracy: 0.8206\n",
            "Epoch 8/500\n",
            "675/675 - 1s - loss: 0.4413 - accuracy: 0.8187 - val_loss: 0.4499 - val_accuracy: 0.8181\n",
            "Epoch 9/500\n",
            "675/675 - 1s - loss: 0.4410 - accuracy: 0.8171 - val_loss: 0.4476 - val_accuracy: 0.8167\n",
            "Epoch 10/500\n",
            "675/675 - 1s - loss: 0.4405 - accuracy: 0.8177 - val_loss: 0.4426 - val_accuracy: 0.8187\n",
            "Epoch 11/500\n",
            "675/675 - 1s - loss: 0.4406 - accuracy: 0.8178 - val_loss: 0.4485 - val_accuracy: 0.8174\n",
            "Epoch 12/500\n",
            "675/675 - 1s - loss: 0.4405 - accuracy: 0.8181 - val_loss: 0.4494 - val_accuracy: 0.8181\n",
            "Epoch 13/500\n",
            "675/675 - 1s - loss: 0.4405 - accuracy: 0.8188 - val_loss: 0.4445 - val_accuracy: 0.8170\n",
            "Epoch 14/500\n",
            "675/675 - 1s - loss: 0.4409 - accuracy: 0.8183 - val_loss: 0.4474 - val_accuracy: 0.8165\n",
            "Epoch 15/500\n",
            "675/675 - 1s - loss: 0.4404 - accuracy: 0.8198 - val_loss: 0.4515 - val_accuracy: 0.8139\n",
            "Epoch 16/500\n",
            "675/675 - 1s - loss: 0.4404 - accuracy: 0.8181 - val_loss: 0.4436 - val_accuracy: 0.8187\n",
            "Epoch 17/500\n",
            "675/675 - 1s - loss: 0.4404 - accuracy: 0.8178 - val_loss: 0.4457 - val_accuracy: 0.8189\n",
            "Epoch 18/500\n",
            "675/675 - 1s - loss: 0.4404 - accuracy: 0.8176 - val_loss: 0.4526 - val_accuracy: 0.8154\n",
            "Epoch 19/500\n",
            "675/675 - 1s - loss: 0.4398 - accuracy: 0.8193 - val_loss: 0.4482 - val_accuracy: 0.8169\n",
            "Epoch 20/500\n",
            "675/675 - 1s - loss: 0.4395 - accuracy: 0.8191 - val_loss: 0.4543 - val_accuracy: 0.8163\n",
            "Epoch 21/500\n",
            "675/675 - 1s - loss: 0.4402 - accuracy: 0.8186 - val_loss: 0.4498 - val_accuracy: 0.8187\n",
            "Epoch 22/500\n",
            "675/675 - 1s - loss: 0.4405 - accuracy: 0.8182 - val_loss: 0.4419 - val_accuracy: 0.8170\n",
            "Epoch 23/500\n",
            "675/675 - 1s - loss: 0.4393 - accuracy: 0.8195 - val_loss: 0.4472 - val_accuracy: 0.8172\n",
            "Epoch 24/500\n",
            "675/675 - 1s - loss: 0.4402 - accuracy: 0.8194 - val_loss: 0.4481 - val_accuracy: 0.8181\n",
            "Epoch 25/500\n",
            "675/675 - 1s - loss: 0.4396 - accuracy: 0.8187 - val_loss: 0.4424 - val_accuracy: 0.8174\n",
            "Epoch 26/500\n",
            "675/675 - 1s - loss: 0.4396 - accuracy: 0.8181 - val_loss: 0.4426 - val_accuracy: 0.8187\n",
            "Epoch 27/500\n",
            "675/675 - 1s - loss: 0.4389 - accuracy: 0.8191 - val_loss: 0.4472 - val_accuracy: 0.8161\n",
            "Epoch 28/500\n",
            "675/675 - 1s - loss: 0.4403 - accuracy: 0.8192 - val_loss: 0.4453 - val_accuracy: 0.8180\n",
            "Epoch 29/500\n",
            "675/675 - 1s - loss: 0.4402 - accuracy: 0.8189 - val_loss: 0.4489 - val_accuracy: 0.8174\n",
            "Epoch 30/500\n",
            "675/675 - 1s - loss: 0.4403 - accuracy: 0.8195 - val_loss: 0.4466 - val_accuracy: 0.8161\n",
            "Epoch 31/500\n",
            "675/675 - 1s - loss: 0.4398 - accuracy: 0.8181 - val_loss: 0.4436 - val_accuracy: 0.8185\n",
            "Epoch 32/500\n",
            "675/675 - 1s - loss: 0.4395 - accuracy: 0.8194 - val_loss: 0.4454 - val_accuracy: 0.8193\n",
            "Epoch 33/500\n",
            "675/675 - 1s - loss: 0.4399 - accuracy: 0.8181 - val_loss: 0.4424 - val_accuracy: 0.8170\n",
            "Epoch 34/500\n",
            "675/675 - 1s - loss: 0.4391 - accuracy: 0.8185 - val_loss: 0.4441 - val_accuracy: 0.8174\n",
            "Epoch 35/500\n",
            "675/675 - 1s - loss: 0.4389 - accuracy: 0.8189 - val_loss: 0.4439 - val_accuracy: 0.8176\n",
            "Epoch 36/500\n",
            "675/675 - 1s - loss: 0.4389 - accuracy: 0.8190 - val_loss: 0.4422 - val_accuracy: 0.8181\n",
            "Epoch 37/500\n",
            "675/675 - 1s - loss: 0.4395 - accuracy: 0.8179 - val_loss: 0.4439 - val_accuracy: 0.8183\n",
            "Epoch 38/500\n",
            "675/675 - 1s - loss: 0.4390 - accuracy: 0.8185 - val_loss: 0.4435 - val_accuracy: 0.8170\n",
            "Epoch 39/500\n",
            "675/675 - 1s - loss: 0.4384 - accuracy: 0.8182 - val_loss: 0.4452 - val_accuracy: 0.8165\n",
            "Epoch 40/500\n",
            "675/675 - 1s - loss: 0.4389 - accuracy: 0.8198 - val_loss: 0.4445 - val_accuracy: 0.8180\n",
            "Epoch 41/500\n",
            "675/675 - 1s - loss: 0.4393 - accuracy: 0.8181 - val_loss: 0.4402 - val_accuracy: 0.8159\n",
            "Epoch 42/500\n",
            "675/675 - 1s - loss: 0.4387 - accuracy: 0.8188 - val_loss: 0.4418 - val_accuracy: 0.8167\n",
            "Epoch 43/500\n",
            "675/675 - 1s - loss: 0.4386 - accuracy: 0.8190 - val_loss: 0.4455 - val_accuracy: 0.8159\n",
            "Epoch 44/500\n",
            "675/675 - 1s - loss: 0.4381 - accuracy: 0.8176 - val_loss: 0.4527 - val_accuracy: 0.8143\n",
            "Epoch 45/500\n",
            "675/675 - 1s - loss: 0.4392 - accuracy: 0.8175 - val_loss: 0.4421 - val_accuracy: 0.8170\n",
            "Epoch 46/500\n",
            "675/675 - 1s - loss: 0.4386 - accuracy: 0.8186 - val_loss: 0.4479 - val_accuracy: 0.8163\n",
            "Epoch 47/500\n",
            "675/675 - 1s - loss: 0.4391 - accuracy: 0.8182 - val_loss: 0.4434 - val_accuracy: 0.8170\n",
            "Epoch 48/500\n",
            "675/675 - 1s - loss: 0.4385 - accuracy: 0.8183 - val_loss: 0.4411 - val_accuracy: 0.8167\n",
            "Epoch 49/500\n",
            "675/675 - 1s - loss: 0.4389 - accuracy: 0.8181 - val_loss: 0.4431 - val_accuracy: 0.8172\n",
            "Epoch 50/500\n",
            "675/675 - 1s - loss: 0.4381 - accuracy: 0.8193 - val_loss: 0.4438 - val_accuracy: 0.8167\n",
            "Epoch 51/500\n",
            "675/675 - 1s - loss: 0.4383 - accuracy: 0.8181 - val_loss: 0.4403 - val_accuracy: 0.8165\n",
            "Epoch 52/500\n",
            "675/675 - 1s - loss: 0.4385 - accuracy: 0.8177 - val_loss: 0.4426 - val_accuracy: 0.8183\n",
            "Epoch 53/500\n",
            "675/675 - 1s - loss: 0.4381 - accuracy: 0.8179 - val_loss: 0.4429 - val_accuracy: 0.8174\n",
            "Epoch 54/500\n",
            "675/675 - 1s - loss: 0.4380 - accuracy: 0.8194 - val_loss: 0.4436 - val_accuracy: 0.8172\n",
            "Epoch 55/500\n",
            "675/675 - 1s - loss: 0.4391 - accuracy: 0.8186 - val_loss: 0.4422 - val_accuracy: 0.8169\n",
            "Epoch 56/500\n",
            "675/675 - 1s - loss: 0.4381 - accuracy: 0.8194 - val_loss: 0.4423 - val_accuracy: 0.8157\n",
            "Epoch 57/500\n",
            "675/675 - 1s - loss: 0.4382 - accuracy: 0.8185 - val_loss: 0.4460 - val_accuracy: 0.8176\n",
            "Epoch 58/500\n",
            "675/675 - 1s - loss: 0.4382 - accuracy: 0.8191 - val_loss: 0.4437 - val_accuracy: 0.8180\n",
            "Epoch 59/500\n",
            "675/675 - 1s - loss: 0.4381 - accuracy: 0.8189 - val_loss: 0.4468 - val_accuracy: 0.8159\n",
            "Epoch 60/500\n",
            "675/675 - 1s - loss: 0.4383 - accuracy: 0.8187 - val_loss: 0.4435 - val_accuracy: 0.8185\n",
            "Epoch 61/500\n",
            "675/675 - 1s - loss: 0.4377 - accuracy: 0.8185 - val_loss: 0.4485 - val_accuracy: 0.8176\n",
            "Epoch 62/500\n",
            "675/675 - 1s - loss: 0.4384 - accuracy: 0.8184 - val_loss: 0.4444 - val_accuracy: 0.8169\n",
            "Epoch 63/500\n",
            "675/675 - 1s - loss: 0.4386 - accuracy: 0.8181 - val_loss: 0.4425 - val_accuracy: 0.8176\n",
            "Epoch 64/500\n",
            "675/675 - 1s - loss: 0.4378 - accuracy: 0.8186 - val_loss: 0.4525 - val_accuracy: 0.8174\n",
            "Epoch 65/500\n",
            "675/675 - 1s - loss: 0.4382 - accuracy: 0.8191 - val_loss: 0.4435 - val_accuracy: 0.8169\n",
            "Epoch 66/500\n",
            "675/675 - 1s - loss: 0.4382 - accuracy: 0.8184 - val_loss: 0.4432 - val_accuracy: 0.8181\n",
            "Epoch 67/500\n",
            "675/675 - 1s - loss: 0.4382 - accuracy: 0.8182 - val_loss: 0.4425 - val_accuracy: 0.8180\n",
            "Epoch 68/500\n",
            "675/675 - 1s - loss: 0.4379 - accuracy: 0.8181 - val_loss: 0.4464 - val_accuracy: 0.8161\n",
            "Epoch 69/500\n",
            "675/675 - 1s - loss: 0.4383 - accuracy: 0.8185 - val_loss: 0.4459 - val_accuracy: 0.8169\n",
            "Epoch 70/500\n",
            "675/675 - 1s - loss: 0.4384 - accuracy: 0.8187 - val_loss: 0.4409 - val_accuracy: 0.8170\n",
            "Epoch 71/500\n",
            "675/675 - 1s - loss: 0.4377 - accuracy: 0.8186 - val_loss: 0.4412 - val_accuracy: 0.8180\n",
            "Epoch 72/500\n",
            "675/675 - 1s - loss: 0.4375 - accuracy: 0.8185 - val_loss: 0.4411 - val_accuracy: 0.8170\n",
            "Epoch 73/500\n",
            "675/675 - 1s - loss: 0.4385 - accuracy: 0.8200 - val_loss: 0.4442 - val_accuracy: 0.8181\n",
            "Epoch 74/500\n",
            "675/675 - 1s - loss: 0.4381 - accuracy: 0.8188 - val_loss: 0.4403 - val_accuracy: 0.8174\n",
            "Epoch 75/500\n",
            "675/675 - 1s - loss: 0.4374 - accuracy: 0.8184 - val_loss: 0.4456 - val_accuracy: 0.8165\n",
            "Epoch 76/500\n",
            "675/675 - 1s - loss: 0.4383 - accuracy: 0.8186 - val_loss: 0.4455 - val_accuracy: 0.8187\n",
            "Epoch 77/500\n",
            "675/675 - 1s - loss: 0.4376 - accuracy: 0.8186 - val_loss: 0.4471 - val_accuracy: 0.8172\n",
            "Epoch 78/500\n",
            "675/675 - 1s - loss: 0.4377 - accuracy: 0.8195 - val_loss: 0.4410 - val_accuracy: 0.8165\n",
            "Epoch 79/500\n",
            "675/675 - 1s - loss: 0.4371 - accuracy: 0.8189 - val_loss: 0.4467 - val_accuracy: 0.8156\n",
            "Epoch 80/500\n",
            "675/675 - 1s - loss: 0.4376 - accuracy: 0.8192 - val_loss: 0.4409 - val_accuracy: 0.8176\n",
            "Epoch 81/500\n",
            "675/675 - 1s - loss: 0.4370 - accuracy: 0.8173 - val_loss: 0.4574 - val_accuracy: 0.8146\n",
            "Epoch 82/500\n",
            "675/675 - 1s - loss: 0.4384 - accuracy: 0.8186 - val_loss: 0.4408 - val_accuracy: 0.8165\n",
            "Epoch 83/500\n",
            "675/675 - 1s - loss: 0.4379 - accuracy: 0.8184 - val_loss: 0.4446 - val_accuracy: 0.8183\n",
            "Epoch 84/500\n",
            "675/675 - 1s - loss: 0.4376 - accuracy: 0.8181 - val_loss: 0.4439 - val_accuracy: 0.8180\n",
            "Epoch 85/500\n",
            "675/675 - 1s - loss: 0.4381 - accuracy: 0.8189 - val_loss: 0.4414 - val_accuracy: 0.8161\n",
            "Epoch 86/500\n",
            "675/675 - 1s - loss: 0.4376 - accuracy: 0.8172 - val_loss: 0.4424 - val_accuracy: 0.8169\n",
            "Epoch 87/500\n",
            "675/675 - 1s - loss: 0.4370 - accuracy: 0.8181 - val_loss: 0.4443 - val_accuracy: 0.8157\n",
            "Epoch 88/500\n",
            "675/675 - 1s - loss: 0.4380 - accuracy: 0.8175 - val_loss: 0.4406 - val_accuracy: 0.8167\n",
            "Epoch 89/500\n",
            "675/675 - 1s - loss: 0.4374 - accuracy: 0.8189 - val_loss: 0.4443 - val_accuracy: 0.8181\n",
            "Epoch 90/500\n",
            "675/675 - 1s - loss: 0.4372 - accuracy: 0.8193 - val_loss: 0.4414 - val_accuracy: 0.8163\n",
            "Epoch 91/500\n",
            "675/675 - 1s - loss: 0.4368 - accuracy: 0.8189 - val_loss: 0.4415 - val_accuracy: 0.8183\n",
            "Epoch 92/500\n",
            "675/675 - 1s - loss: 0.4372 - accuracy: 0.8186 - val_loss: 0.4435 - val_accuracy: 0.8157\n",
            "Epoch 93/500\n",
            "675/675 - 1s - loss: 0.4380 - accuracy: 0.8184 - val_loss: 0.4438 - val_accuracy: 0.8157\n",
            "Epoch 94/500\n",
            "675/675 - 1s - loss: 0.4374 - accuracy: 0.8186 - val_loss: 0.4444 - val_accuracy: 0.8165\n",
            "Epoch 95/500\n",
            "675/675 - 1s - loss: 0.4364 - accuracy: 0.8194 - val_loss: 0.4459 - val_accuracy: 0.8159\n",
            "Epoch 96/500\n",
            "675/675 - 1s - loss: 0.4374 - accuracy: 0.8191 - val_loss: 0.4460 - val_accuracy: 0.8169\n",
            "Epoch 97/500\n",
            "675/675 - 1s - loss: 0.4375 - accuracy: 0.8195 - val_loss: 0.4426 - val_accuracy: 0.8170\n",
            "Epoch 98/500\n",
            "675/675 - 1s - loss: 0.4375 - accuracy: 0.8177 - val_loss: 0.4404 - val_accuracy: 0.8181\n",
            "Epoch 99/500\n",
            "675/675 - 1s - loss: 0.4378 - accuracy: 0.8188 - val_loss: 0.4418 - val_accuracy: 0.8178\n",
            "Epoch 100/500\n",
            "675/675 - 1s - loss: 0.4369 - accuracy: 0.8187 - val_loss: 0.4420 - val_accuracy: 0.8157\n",
            "Epoch 101/500\n",
            "675/675 - 1s - loss: 0.4369 - accuracy: 0.8188 - val_loss: 0.4401 - val_accuracy: 0.8180\n",
            "Epoch 102/500\n",
            "675/675 - 1s - loss: 0.4370 - accuracy: 0.8180 - val_loss: 0.4477 - val_accuracy: 0.8143\n",
            "Epoch 103/500\n",
            "675/675 - 1s - loss: 0.4373 - accuracy: 0.8184 - val_loss: 0.4436 - val_accuracy: 0.8170\n",
            "Epoch 104/500\n",
            "675/675 - 1s - loss: 0.4372 - accuracy: 0.8170 - val_loss: 0.4442 - val_accuracy: 0.8187\n",
            "Epoch 105/500\n",
            "675/675 - 1s - loss: 0.4375 - accuracy: 0.8189 - val_loss: 0.4447 - val_accuracy: 0.8170\n",
            "Epoch 106/500\n",
            "675/675 - 1s - loss: 0.4373 - accuracy: 0.8186 - val_loss: 0.4531 - val_accuracy: 0.8150\n",
            "Epoch 107/500\n",
            "675/675 - 1s - loss: 0.4370 - accuracy: 0.8183 - val_loss: 0.4467 - val_accuracy: 0.8169\n",
            "Epoch 108/500\n",
            "675/675 - 1s - loss: 0.4377 - accuracy: 0.8191 - val_loss: 0.4425 - val_accuracy: 0.8161\n",
            "Epoch 109/500\n",
            "675/675 - 1s - loss: 0.4373 - accuracy: 0.8181 - val_loss: 0.4416 - val_accuracy: 0.8172\n",
            "Epoch 110/500\n",
            "675/675 - 1s - loss: 0.4370 - accuracy: 0.8194 - val_loss: 0.4449 - val_accuracy: 0.8178\n",
            "Epoch 111/500\n",
            "675/675 - 1s - loss: 0.4370 - accuracy: 0.8184 - val_loss: 0.4464 - val_accuracy: 0.8174\n",
            "Epoch 112/500\n",
            "675/675 - 1s - loss: 0.4374 - accuracy: 0.8181 - val_loss: 0.4411 - val_accuracy: 0.8174\n",
            "Epoch 113/500\n",
            "675/675 - 1s - loss: 0.4370 - accuracy: 0.8185 - val_loss: 0.4412 - val_accuracy: 0.8174\n",
            "Epoch 114/500\n",
            "675/675 - 1s - loss: 0.4370 - accuracy: 0.8183 - val_loss: 0.4440 - val_accuracy: 0.8189\n",
            "Epoch 115/500\n",
            "675/675 - 1s - loss: 0.4377 - accuracy: 0.8183 - val_loss: 0.4423 - val_accuracy: 0.8169\n",
            "Epoch 116/500\n",
            "675/675 - 1s - loss: 0.4374 - accuracy: 0.8178 - val_loss: 0.4440 - val_accuracy: 0.8152\n",
            "Epoch 117/500\n",
            "675/675 - 1s - loss: 0.4367 - accuracy: 0.8188 - val_loss: 0.4413 - val_accuracy: 0.8161\n",
            "Epoch 118/500\n",
            "675/675 - 1s - loss: 0.4378 - accuracy: 0.8192 - val_loss: 0.4459 - val_accuracy: 0.8174\n",
            "Epoch 119/500\n",
            "675/675 - 1s - loss: 0.4365 - accuracy: 0.8206 - val_loss: 0.4403 - val_accuracy: 0.8169\n",
            "Epoch 120/500\n",
            "675/675 - 1s - loss: 0.4372 - accuracy: 0.8183 - val_loss: 0.4445 - val_accuracy: 0.8165\n",
            "Epoch 121/500\n",
            "675/675 - 1s - loss: 0.4374 - accuracy: 0.8187 - val_loss: 0.4493 - val_accuracy: 0.8150\n",
            "Epoch 122/500\n",
            "675/675 - 1s - loss: 0.4369 - accuracy: 0.8185 - val_loss: 0.4428 - val_accuracy: 0.8196\n",
            "Epoch 123/500\n",
            "675/675 - 1s - loss: 0.4371 - accuracy: 0.8183 - val_loss: 0.4466 - val_accuracy: 0.8169\n",
            "Epoch 124/500\n",
            "675/675 - 1s - loss: 0.4366 - accuracy: 0.8182 - val_loss: 0.4481 - val_accuracy: 0.8204\n",
            "Epoch 125/500\n",
            "675/675 - 1s - loss: 0.4364 - accuracy: 0.8197 - val_loss: 0.4434 - val_accuracy: 0.8194\n",
            "Epoch 126/500\n",
            "675/675 - 1s - loss: 0.4370 - accuracy: 0.8187 - val_loss: 0.4409 - val_accuracy: 0.8163\n",
            "Epoch 127/500\n",
            "675/675 - 1s - loss: 0.4371 - accuracy: 0.8179 - val_loss: 0.4434 - val_accuracy: 0.8161\n",
            "Epoch 128/500\n",
            "675/675 - 1s - loss: 0.4369 - accuracy: 0.8189 - val_loss: 0.4437 - val_accuracy: 0.8146\n",
            "Epoch 129/500\n",
            "675/675 - 1s - loss: 0.4365 - accuracy: 0.8195 - val_loss: 0.4429 - val_accuracy: 0.8157\n",
            "Epoch 130/500\n",
            "675/675 - 1s - loss: 0.4371 - accuracy: 0.8173 - val_loss: 0.4460 - val_accuracy: 0.8170\n",
            "Epoch 131/500\n",
            "675/675 - 1s - loss: 0.4371 - accuracy: 0.8181 - val_loss: 0.4441 - val_accuracy: 0.8152\n",
            "Epoch 132/500\n",
            "675/675 - 1s - loss: 0.4367 - accuracy: 0.8177 - val_loss: 0.4426 - val_accuracy: 0.8165\n",
            "Epoch 133/500\n",
            "675/675 - 1s - loss: 0.4374 - accuracy: 0.8186 - val_loss: 0.4423 - val_accuracy: 0.8172\n",
            "Epoch 134/500\n",
            "675/675 - 1s - loss: 0.4369 - accuracy: 0.8190 - val_loss: 0.4456 - val_accuracy: 0.8174\n",
            "Epoch 135/500\n",
            "675/675 - 1s - loss: 0.4363 - accuracy: 0.8191 - val_loss: 0.4484 - val_accuracy: 0.8157\n",
            "Epoch 136/500\n",
            "675/675 - 1s - loss: 0.4376 - accuracy: 0.8185 - val_loss: 0.4406 - val_accuracy: 0.8165\n",
            "Epoch 137/500\n",
            "675/675 - 1s - loss: 0.4368 - accuracy: 0.8186 - val_loss: 0.4446 - val_accuracy: 0.8157\n",
            "Epoch 138/500\n",
            "675/675 - 1s - loss: 0.4368 - accuracy: 0.8192 - val_loss: 0.4446 - val_accuracy: 0.8163\n",
            "Epoch 139/500\n",
            "675/675 - 1s - loss: 0.4363 - accuracy: 0.8185 - val_loss: 0.4438 - val_accuracy: 0.8161\n",
            "Epoch 140/500\n",
            "675/675 - 1s - loss: 0.4371 - accuracy: 0.8189 - val_loss: 0.4422 - val_accuracy: 0.8163\n",
            "Epoch 141/500\n",
            "675/675 - 1s - loss: 0.4374 - accuracy: 0.8192 - val_loss: 0.4459 - val_accuracy: 0.8165\n",
            "Epoch 142/500\n",
            "675/675 - 1s - loss: 0.4365 - accuracy: 0.8192 - val_loss: 0.4429 - val_accuracy: 0.8157\n",
            "Epoch 143/500\n",
            "675/675 - 1s - loss: 0.4365 - accuracy: 0.8197 - val_loss: 0.4508 - val_accuracy: 0.8150\n",
            "Epoch 144/500\n",
            "675/675 - 1s - loss: 0.4364 - accuracy: 0.8191 - val_loss: 0.4446 - val_accuracy: 0.8169\n",
            "Epoch 145/500\n",
            "675/675 - 1s - loss: 0.4374 - accuracy: 0.8179 - val_loss: 0.4402 - val_accuracy: 0.8178\n",
            "Epoch 146/500\n",
            "675/675 - 1s - loss: 0.4368 - accuracy: 0.8198 - val_loss: 0.4416 - val_accuracy: 0.8174\n",
            "Epoch 147/500\n",
            "675/675 - 1s - loss: 0.4369 - accuracy: 0.8190 - val_loss: 0.4397 - val_accuracy: 0.8163\n",
            "Epoch 148/500\n",
            "675/675 - 1s - loss: 0.4366 - accuracy: 0.8188 - val_loss: 0.4442 - val_accuracy: 0.8163\n",
            "Epoch 149/500\n",
            "675/675 - 1s - loss: 0.4373 - accuracy: 0.8188 - val_loss: 0.4491 - val_accuracy: 0.8167\n",
            "Epoch 150/500\n",
            "675/675 - 1s - loss: 0.4365 - accuracy: 0.8186 - val_loss: 0.4557 - val_accuracy: 0.8156\n",
            "Epoch 151/500\n",
            "675/675 - 1s - loss: 0.4364 - accuracy: 0.8186 - val_loss: 0.4437 - val_accuracy: 0.8187\n",
            "Epoch 152/500\n",
            "675/675 - 1s - loss: 0.4369 - accuracy: 0.8189 - val_loss: 0.4408 - val_accuracy: 0.8172\n",
            "Epoch 153/500\n",
            "675/675 - 1s - loss: 0.4368 - accuracy: 0.8188 - val_loss: 0.4434 - val_accuracy: 0.8189\n",
            "Epoch 154/500\n",
            "675/675 - 1s - loss: 0.4366 - accuracy: 0.8180 - val_loss: 0.4472 - val_accuracy: 0.8156\n",
            "Epoch 155/500\n",
            "675/675 - 1s - loss: 0.4375 - accuracy: 0.8175 - val_loss: 0.4425 - val_accuracy: 0.8146\n",
            "Epoch 156/500\n",
            "675/675 - 1s - loss: 0.4368 - accuracy: 0.8184 - val_loss: 0.4417 - val_accuracy: 0.8174\n",
            "Epoch 157/500\n",
            "675/675 - 1s - loss: 0.4371 - accuracy: 0.8183 - val_loss: 0.4456 - val_accuracy: 0.8178\n",
            "Epoch 158/500\n",
            "675/675 - 1s - loss: 0.4368 - accuracy: 0.8182 - val_loss: 0.4434 - val_accuracy: 0.8167\n",
            "Epoch 159/500\n",
            "675/675 - 1s - loss: 0.4368 - accuracy: 0.8198 - val_loss: 0.4407 - val_accuracy: 0.8174\n",
            "Epoch 160/500\n",
            "675/675 - 1s - loss: 0.4367 - accuracy: 0.8181 - val_loss: 0.4432 - val_accuracy: 0.8172\n",
            "Epoch 161/500\n",
            "675/675 - 1s - loss: 0.4365 - accuracy: 0.8200 - val_loss: 0.4437 - val_accuracy: 0.8161\n",
            "Epoch 162/500\n",
            "675/675 - 1s - loss: 0.4369 - accuracy: 0.8192 - val_loss: 0.4439 - val_accuracy: 0.8156\n",
            "Epoch 163/500\n",
            "675/675 - 1s - loss: 0.4372 - accuracy: 0.8191 - val_loss: 0.4423 - val_accuracy: 0.8176\n",
            "Epoch 164/500\n",
            "675/675 - 1s - loss: 0.4370 - accuracy: 0.8189 - val_loss: 0.4453 - val_accuracy: 0.8178\n",
            "Epoch 165/500\n",
            "675/675 - 1s - loss: 0.4365 - accuracy: 0.8197 - val_loss: 0.4452 - val_accuracy: 0.8167\n",
            "Epoch 166/500\n",
            "675/675 - 1s - loss: 0.4372 - accuracy: 0.8197 - val_loss: 0.4410 - val_accuracy: 0.8156\n",
            "Epoch 167/500\n",
            "675/675 - 1s - loss: 0.4365 - accuracy: 0.8195 - val_loss: 0.4426 - val_accuracy: 0.8159\n",
            "Epoch 168/500\n",
            "675/675 - 1s - loss: 0.4368 - accuracy: 0.8194 - val_loss: 0.4458 - val_accuracy: 0.8167\n",
            "Epoch 169/500\n",
            "675/675 - 1s - loss: 0.4366 - accuracy: 0.8183 - val_loss: 0.4457 - val_accuracy: 0.8146\n",
            "Epoch 170/500\n",
            "675/675 - 1s - loss: 0.4367 - accuracy: 0.8192 - val_loss: 0.4456 - val_accuracy: 0.8157\n",
            "Epoch 171/500\n",
            "675/675 - 1s - loss: 0.4370 - accuracy: 0.8185 - val_loss: 0.4440 - val_accuracy: 0.8174\n",
            "Epoch 172/500\n",
            "675/675 - 1s - loss: 0.4365 - accuracy: 0.8195 - val_loss: 0.4446 - val_accuracy: 0.8150\n",
            "Epoch 173/500\n",
            "675/675 - 1s - loss: 0.4372 - accuracy: 0.8197 - val_loss: 0.4437 - val_accuracy: 0.8159\n",
            "Epoch 174/500\n",
            "675/675 - 1s - loss: 0.4370 - accuracy: 0.8200 - val_loss: 0.4443 - val_accuracy: 0.8161\n",
            "Epoch 175/500\n",
            "675/675 - 1s - loss: 0.4367 - accuracy: 0.8188 - val_loss: 0.4476 - val_accuracy: 0.8176\n",
            "Epoch 176/500\n",
            "675/675 - 1s - loss: 0.4379 - accuracy: 0.8195 - val_loss: 0.4405 - val_accuracy: 0.8167\n",
            "Epoch 177/500\n",
            "675/675 - 1s - loss: 0.4365 - accuracy: 0.8191 - val_loss: 0.4435 - val_accuracy: 0.8167\n",
            "Epoch 178/500\n",
            "675/675 - 1s - loss: 0.4372 - accuracy: 0.8189 - val_loss: 0.4436 - val_accuracy: 0.8169\n",
            "Epoch 179/500\n",
            "675/675 - 1s - loss: 0.4371 - accuracy: 0.8183 - val_loss: 0.4462 - val_accuracy: 0.8154\n",
            "Epoch 180/500\n",
            "675/675 - 1s - loss: 0.4369 - accuracy: 0.8180 - val_loss: 0.4460 - val_accuracy: 0.8156\n",
            "Epoch 181/500\n",
            "675/675 - 1s - loss: 0.4369 - accuracy: 0.8181 - val_loss: 0.4438 - val_accuracy: 0.8163\n",
            "Epoch 182/500\n",
            "675/675 - 1s - loss: 0.4361 - accuracy: 0.8186 - val_loss: 0.4440 - val_accuracy: 0.8165\n",
            "Epoch 183/500\n",
            "675/675 - 1s - loss: 0.4375 - accuracy: 0.8189 - val_loss: 0.4464 - val_accuracy: 0.8152\n",
            "Epoch 184/500\n",
            "675/675 - 1s - loss: 0.4366 - accuracy: 0.8192 - val_loss: 0.4467 - val_accuracy: 0.8159\n",
            "Epoch 185/500\n",
            "675/675 - 1s - loss: 0.4371 - accuracy: 0.8192 - val_loss: 0.4427 - val_accuracy: 0.8157\n",
            "Epoch 186/500\n",
            "675/675 - 1s - loss: 0.4371 - accuracy: 0.8194 - val_loss: 0.4421 - val_accuracy: 0.8170\n",
            "Epoch 187/500\n",
            "675/675 - 1s - loss: 0.4370 - accuracy: 0.8189 - val_loss: 0.4436 - val_accuracy: 0.8161\n",
            "Epoch 188/500\n",
            "675/675 - 1s - loss: 0.4370 - accuracy: 0.8184 - val_loss: 0.4430 - val_accuracy: 0.8163\n",
            "Epoch 189/500\n",
            "675/675 - 1s - loss: 0.4371 - accuracy: 0.8178 - val_loss: 0.4480 - val_accuracy: 0.8156\n",
            "Epoch 190/500\n",
            "675/675 - 1s - loss: 0.4369 - accuracy: 0.8182 - val_loss: 0.4435 - val_accuracy: 0.8163\n",
            "Epoch 191/500\n",
            "675/675 - 1s - loss: 0.4367 - accuracy: 0.8188 - val_loss: 0.4435 - val_accuracy: 0.8161\n",
            "Epoch 192/500\n",
            "675/675 - 1s - loss: 0.4364 - accuracy: 0.8183 - val_loss: 0.4430 - val_accuracy: 0.8170\n",
            "Epoch 193/500\n",
            "675/675 - 1s - loss: 0.4365 - accuracy: 0.8200 - val_loss: 0.4390 - val_accuracy: 0.8159\n",
            "Epoch 194/500\n",
            "675/675 - 1s - loss: 0.4367 - accuracy: 0.8169 - val_loss: 0.4411 - val_accuracy: 0.8183\n",
            "Epoch 195/500\n",
            "675/675 - 1s - loss: 0.4367 - accuracy: 0.8180 - val_loss: 0.4478 - val_accuracy: 0.8172\n",
            "Epoch 196/500\n",
            "675/675 - 1s - loss: 0.4367 - accuracy: 0.8190 - val_loss: 0.4416 - val_accuracy: 0.8157\n",
            "Epoch 197/500\n",
            "675/675 - 1s - loss: 0.4367 - accuracy: 0.8183 - val_loss: 0.4435 - val_accuracy: 0.8165\n",
            "Epoch 198/500\n",
            "675/675 - 1s - loss: 0.4368 - accuracy: 0.8187 - val_loss: 0.4430 - val_accuracy: 0.8163\n",
            "Epoch 199/500\n",
            "675/675 - 1s - loss: 0.4367 - accuracy: 0.8190 - val_loss: 0.4421 - val_accuracy: 0.8170\n",
            "Epoch 200/500\n",
            "675/675 - 1s - loss: 0.4364 - accuracy: 0.8192 - val_loss: 0.4451 - val_accuracy: 0.8178\n",
            "Epoch 201/500\n",
            "675/675 - 1s - loss: 0.4368 - accuracy: 0.8196 - val_loss: 0.4448 - val_accuracy: 0.8159\n",
            "Epoch 202/500\n",
            "675/675 - 1s - loss: 0.4365 - accuracy: 0.8177 - val_loss: 0.4449 - val_accuracy: 0.8191\n",
            "Epoch 203/500\n",
            "675/675 - 1s - loss: 0.4364 - accuracy: 0.8198 - val_loss: 0.4456 - val_accuracy: 0.8167\n",
            "Epoch 204/500\n",
            "675/675 - 1s - loss: 0.4373 - accuracy: 0.8193 - val_loss: 0.4407 - val_accuracy: 0.8154\n",
            "Epoch 205/500\n",
            "675/675 - 1s - loss: 0.4368 - accuracy: 0.8183 - val_loss: 0.4406 - val_accuracy: 0.8169\n",
            "Epoch 206/500\n",
            "675/675 - 1s - loss: 0.4372 - accuracy: 0.8187 - val_loss: 0.4475 - val_accuracy: 0.8157\n",
            "Epoch 207/500\n",
            "675/675 - 1s - loss: 0.4370 - accuracy: 0.8190 - val_loss: 0.4408 - val_accuracy: 0.8156\n",
            "Epoch 208/500\n",
            "675/675 - 1s - loss: 0.4365 - accuracy: 0.8196 - val_loss: 0.4475 - val_accuracy: 0.8169\n",
            "Epoch 209/500\n",
            "675/675 - 1s - loss: 0.4378 - accuracy: 0.8188 - val_loss: 0.4411 - val_accuracy: 0.8167\n",
            "Epoch 210/500\n",
            "675/675 - 1s - loss: 0.4362 - accuracy: 0.8189 - val_loss: 0.4425 - val_accuracy: 0.8169\n",
            "Epoch 211/500\n",
            "675/675 - 1s - loss: 0.4369 - accuracy: 0.8180 - val_loss: 0.4440 - val_accuracy: 0.8176\n",
            "Epoch 212/500\n",
            "675/675 - 1s - loss: 0.4370 - accuracy: 0.8192 - val_loss: 0.4411 - val_accuracy: 0.8174\n",
            "Epoch 213/500\n",
            "675/675 - 1s - loss: 0.4363 - accuracy: 0.8183 - val_loss: 0.4428 - val_accuracy: 0.8152\n",
            "Epoch 214/500\n",
            "675/675 - 1s - loss: 0.4372 - accuracy: 0.8185 - val_loss: 0.4445 - val_accuracy: 0.8152\n",
            "Epoch 215/500\n",
            "675/675 - 1s - loss: 0.4369 - accuracy: 0.8187 - val_loss: 0.4435 - val_accuracy: 0.8165\n",
            "Epoch 216/500\n",
            "675/675 - 1s - loss: 0.4371 - accuracy: 0.8181 - val_loss: 0.4427 - val_accuracy: 0.8178\n",
            "Epoch 217/500\n",
            "675/675 - 1s - loss: 0.4363 - accuracy: 0.8197 - val_loss: 0.4510 - val_accuracy: 0.8161\n",
            "Epoch 218/500\n",
            "675/675 - 1s - loss: 0.4368 - accuracy: 0.8192 - val_loss: 0.4421 - val_accuracy: 0.8157\n",
            "Epoch 219/500\n",
            "675/675 - 1s - loss: 0.4370 - accuracy: 0.8185 - val_loss: 0.4459 - val_accuracy: 0.8159\n",
            "Epoch 220/500\n",
            "675/675 - 1s - loss: 0.4372 - accuracy: 0.8190 - val_loss: 0.4432 - val_accuracy: 0.8163\n",
            "Epoch 221/500\n",
            "675/675 - 1s - loss: 0.4368 - accuracy: 0.8192 - val_loss: 0.4388 - val_accuracy: 0.8172\n",
            "Epoch 222/500\n",
            "675/675 - 1s - loss: 0.4365 - accuracy: 0.8178 - val_loss: 0.4441 - val_accuracy: 0.8148\n",
            "Epoch 223/500\n",
            "675/675 - 1s - loss: 0.4376 - accuracy: 0.8187 - val_loss: 0.4446 - val_accuracy: 0.8170\n",
            "Epoch 224/500\n",
            "675/675 - 1s - loss: 0.4365 - accuracy: 0.8180 - val_loss: 0.4397 - val_accuracy: 0.8165\n",
            "Epoch 225/500\n",
            "675/675 - 1s - loss: 0.4366 - accuracy: 0.8191 - val_loss: 0.4408 - val_accuracy: 0.8156\n",
            "Epoch 226/500\n",
            "675/675 - 1s - loss: 0.4362 - accuracy: 0.8192 - val_loss: 0.4417 - val_accuracy: 0.8189\n",
            "Epoch 227/500\n",
            "675/675 - 1s - loss: 0.4369 - accuracy: 0.8182 - val_loss: 0.4446 - val_accuracy: 0.8165\n",
            "Epoch 228/500\n",
            "675/675 - 1s - loss: 0.4365 - accuracy: 0.8195 - val_loss: 0.4446 - val_accuracy: 0.8169\n",
            "Epoch 229/500\n",
            "675/675 - 1s - loss: 0.4368 - accuracy: 0.8182 - val_loss: 0.4535 - val_accuracy: 0.8144\n",
            "Epoch 230/500\n",
            "675/675 - 1s - loss: 0.4373 - accuracy: 0.8197 - val_loss: 0.4430 - val_accuracy: 0.8185\n",
            "Epoch 231/500\n",
            "675/675 - 1s - loss: 0.4371 - accuracy: 0.8182 - val_loss: 0.4426 - val_accuracy: 0.8180\n",
            "Epoch 232/500\n",
            "675/675 - 1s - loss: 0.4386 - accuracy: 0.8181 - val_loss: 0.4439 - val_accuracy: 0.8156\n",
            "Epoch 233/500\n",
            "675/675 - 1s - loss: 0.4365 - accuracy: 0.8181 - val_loss: 0.4418 - val_accuracy: 0.8172\n",
            "Epoch 234/500\n",
            "675/675 - 1s - loss: 0.4363 - accuracy: 0.8190 - val_loss: 0.4420 - val_accuracy: 0.8169\n",
            "Epoch 235/500\n",
            "675/675 - 1s - loss: 0.4361 - accuracy: 0.8181 - val_loss: 0.4456 - val_accuracy: 0.8143\n",
            "Epoch 236/500\n",
            "675/675 - 1s - loss: 0.4365 - accuracy: 0.8191 - val_loss: 0.4428 - val_accuracy: 0.8176\n",
            "Epoch 237/500\n",
            "675/675 - 1s - loss: 0.4363 - accuracy: 0.8191 - val_loss: 0.4421 - val_accuracy: 0.8144\n",
            "Epoch 238/500\n",
            "675/675 - 1s - loss: 0.4365 - accuracy: 0.8189 - val_loss: 0.4404 - val_accuracy: 0.8172\n",
            "Epoch 239/500\n",
            "675/675 - 1s - loss: 0.4369 - accuracy: 0.8194 - val_loss: 0.4447 - val_accuracy: 0.8157\n",
            "Epoch 240/500\n",
            "675/675 - 1s - loss: 0.4370 - accuracy: 0.8175 - val_loss: 0.4397 - val_accuracy: 0.8180\n",
            "Epoch 241/500\n",
            "675/675 - 1s - loss: 0.4364 - accuracy: 0.8190 - val_loss: 0.4445 - val_accuracy: 0.8169\n",
            "Epoch 242/500\n",
            "675/675 - 1s - loss: 0.4377 - accuracy: 0.8187 - val_loss: 0.4451 - val_accuracy: 0.8165\n",
            "Epoch 243/500\n",
            "675/675 - 1s - loss: 0.4364 - accuracy: 0.8190 - val_loss: 0.4422 - val_accuracy: 0.8150\n",
            "Epoch 244/500\n",
            "675/675 - 1s - loss: 0.4367 - accuracy: 0.8205 - val_loss: 0.4455 - val_accuracy: 0.8157\n",
            "Epoch 245/500\n",
            "675/675 - 1s - loss: 0.4365 - accuracy: 0.8189 - val_loss: 0.4407 - val_accuracy: 0.8161\n",
            "Epoch 246/500\n",
            "675/675 - 1s - loss: 0.4366 - accuracy: 0.8179 - val_loss: 0.4414 - val_accuracy: 0.8178\n",
            "Epoch 247/500\n",
            "675/675 - 1s - loss: 0.4373 - accuracy: 0.8194 - val_loss: 0.4460 - val_accuracy: 0.8167\n",
            "Epoch 248/500\n",
            "675/675 - 1s - loss: 0.4370 - accuracy: 0.8188 - val_loss: 0.4391 - val_accuracy: 0.8167\n",
            "Epoch 249/500\n",
            "675/675 - 1s - loss: 0.4361 - accuracy: 0.8186 - val_loss: 0.4559 - val_accuracy: 0.8165\n",
            "Epoch 250/500\n",
            "675/675 - 1s - loss: 0.4368 - accuracy: 0.8189 - val_loss: 0.4405 - val_accuracy: 0.8170\n",
            "Epoch 251/500\n",
            "675/675 - 1s - loss: 0.4366 - accuracy: 0.8199 - val_loss: 0.4470 - val_accuracy: 0.8167\n",
            "Epoch 252/500\n",
            "675/675 - 1s - loss: 0.4373 - accuracy: 0.8197 - val_loss: 0.4417 - val_accuracy: 0.8161\n",
            "Epoch 253/500\n",
            "675/675 - 1s - loss: 0.4367 - accuracy: 0.8183 - val_loss: 0.4453 - val_accuracy: 0.8181\n",
            "Epoch 254/500\n",
            "675/675 - 1s - loss: 0.4362 - accuracy: 0.8177 - val_loss: 0.4462 - val_accuracy: 0.8178\n",
            "Epoch 255/500\n",
            "675/675 - 1s - loss: 0.4363 - accuracy: 0.8194 - val_loss: 0.4592 - val_accuracy: 0.8152\n",
            "Epoch 256/500\n",
            "675/675 - 1s - loss: 0.4372 - accuracy: 0.8178 - val_loss: 0.4412 - val_accuracy: 0.8167\n",
            "Epoch 257/500\n",
            "675/675 - 1s - loss: 0.4371 - accuracy: 0.8180 - val_loss: 0.4557 - val_accuracy: 0.8133\n",
            "Epoch 258/500\n",
            "675/675 - 1s - loss: 0.4365 - accuracy: 0.8188 - val_loss: 0.4534 - val_accuracy: 0.8167\n",
            "Epoch 259/500\n",
            "675/675 - 1s - loss: 0.4371 - accuracy: 0.8200 - val_loss: 0.4467 - val_accuracy: 0.8146\n",
            "Epoch 260/500\n",
            "675/675 - 1s - loss: 0.4371 - accuracy: 0.8180 - val_loss: 0.4420 - val_accuracy: 0.8170\n",
            "Epoch 261/500\n",
            "675/675 - 1s - loss: 0.4366 - accuracy: 0.8188 - val_loss: 0.4427 - val_accuracy: 0.8194\n",
            "Epoch 262/500\n",
            "675/675 - 1s - loss: 0.4363 - accuracy: 0.8194 - val_loss: 0.4405 - val_accuracy: 0.8163\n",
            "Epoch 263/500\n",
            "675/675 - 1s - loss: 0.4374 - accuracy: 0.8186 - val_loss: 0.4425 - val_accuracy: 0.8170\n",
            "Epoch 264/500\n",
            "675/675 - 1s - loss: 0.4365 - accuracy: 0.8195 - val_loss: 0.4407 - val_accuracy: 0.8176\n",
            "Epoch 265/500\n",
            "675/675 - 1s - loss: 0.4372 - accuracy: 0.8183 - val_loss: 0.4418 - val_accuracy: 0.8169\n",
            "Epoch 266/500\n",
            "675/675 - 1s - loss: 0.4371 - accuracy: 0.8183 - val_loss: 0.4442 - val_accuracy: 0.8176\n",
            "Epoch 267/500\n",
            "675/675 - 1s - loss: 0.4365 - accuracy: 0.8189 - val_loss: 0.4440 - val_accuracy: 0.8167\n",
            "Epoch 268/500\n",
            "675/675 - 1s - loss: 0.4367 - accuracy: 0.8186 - val_loss: 0.4405 - val_accuracy: 0.8163\n",
            "Epoch 269/500\n",
            "675/675 - 1s - loss: 0.4366 - accuracy: 0.8186 - val_loss: 0.4486 - val_accuracy: 0.8163\n",
            "Epoch 270/500\n",
            "675/675 - 1s - loss: 0.4369 - accuracy: 0.8193 - val_loss: 0.4436 - val_accuracy: 0.8174\n",
            "Epoch 271/500\n",
            "675/675 - 1s - loss: 0.4365 - accuracy: 0.8183 - val_loss: 0.4511 - val_accuracy: 0.8165\n",
            "Epoch 272/500\n",
            "675/675 - 1s - loss: 0.4366 - accuracy: 0.8175 - val_loss: 0.4422 - val_accuracy: 0.8183\n",
            "Epoch 273/500\n",
            "675/675 - 1s - loss: 0.4371 - accuracy: 0.8183 - val_loss: 0.4447 - val_accuracy: 0.8176\n",
            "Epoch 274/500\n",
            "675/675 - 1s - loss: 0.4369 - accuracy: 0.8192 - val_loss: 0.4432 - val_accuracy: 0.8172\n",
            "Epoch 275/500\n",
            "675/675 - 1s - loss: 0.4362 - accuracy: 0.8181 - val_loss: 0.4481 - val_accuracy: 0.8165\n",
            "Epoch 276/500\n",
            "675/675 - 1s - loss: 0.4363 - accuracy: 0.8180 - val_loss: 0.4455 - val_accuracy: 0.8156\n",
            "Epoch 277/500\n",
            "675/675 - 1s - loss: 0.4366 - accuracy: 0.8193 - val_loss: 0.4429 - val_accuracy: 0.8187\n",
            "Epoch 278/500\n",
            "675/675 - 1s - loss: 0.4365 - accuracy: 0.8176 - val_loss: 0.4462 - val_accuracy: 0.8174\n",
            "Epoch 279/500\n",
            "675/675 - 1s - loss: 0.4371 - accuracy: 0.8187 - val_loss: 0.4407 - val_accuracy: 0.8159\n",
            "Epoch 280/500\n",
            "675/675 - 1s - loss: 0.4368 - accuracy: 0.8186 - val_loss: 0.4423 - val_accuracy: 0.8163\n",
            "Epoch 281/500\n",
            "675/675 - 1s - loss: 0.4365 - accuracy: 0.8173 - val_loss: 0.4478 - val_accuracy: 0.8161\n",
            "Epoch 282/500\n",
            "675/675 - 1s - loss: 0.4367 - accuracy: 0.8172 - val_loss: 0.4448 - val_accuracy: 0.8161\n",
            "Epoch 283/500\n",
            "675/675 - 1s - loss: 0.4364 - accuracy: 0.8190 - val_loss: 0.4499 - val_accuracy: 0.8163\n",
            "Epoch 284/500\n",
            "675/675 - 1s - loss: 0.4370 - accuracy: 0.8188 - val_loss: 0.4418 - val_accuracy: 0.8163\n",
            "Epoch 285/500\n",
            "675/675 - 1s - loss: 0.4368 - accuracy: 0.8187 - val_loss: 0.4407 - val_accuracy: 0.8159\n",
            "Epoch 286/500\n",
            "675/675 - 1s - loss: 0.4374 - accuracy: 0.8190 - val_loss: 0.4513 - val_accuracy: 0.8154\n",
            "Epoch 287/500\n",
            "675/675 - 1s - loss: 0.4372 - accuracy: 0.8188 - val_loss: 0.4433 - val_accuracy: 0.8163\n",
            "Epoch 288/500\n",
            "675/675 - 1s - loss: 0.4365 - accuracy: 0.8184 - val_loss: 0.4454 - val_accuracy: 0.8157\n",
            "Epoch 289/500\n",
            "675/675 - 1s - loss: 0.4374 - accuracy: 0.8180 - val_loss: 0.4410 - val_accuracy: 0.8178\n",
            "Epoch 290/500\n",
            "675/675 - 1s - loss: 0.4367 - accuracy: 0.8197 - val_loss: 0.4462 - val_accuracy: 0.8152\n",
            "Epoch 291/500\n",
            "675/675 - 1s - loss: 0.4368 - accuracy: 0.8186 - val_loss: 0.4411 - val_accuracy: 0.8189\n",
            "Epoch 292/500\n",
            "675/675 - 1s - loss: 0.4370 - accuracy: 0.8177 - val_loss: 0.4439 - val_accuracy: 0.8178\n",
            "Epoch 293/500\n",
            "675/675 - 1s - loss: 0.4366 - accuracy: 0.8192 - val_loss: 0.4408 - val_accuracy: 0.8156\n",
            "Epoch 294/500\n",
            "675/675 - 1s - loss: 0.4364 - accuracy: 0.8192 - val_loss: 0.4494 - val_accuracy: 0.8152\n",
            "Epoch 295/500\n",
            "675/675 - 1s - loss: 0.4372 - accuracy: 0.8191 - val_loss: 0.4422 - val_accuracy: 0.8167\n",
            "Epoch 296/500\n",
            "675/675 - 1s - loss: 0.4365 - accuracy: 0.8183 - val_loss: 0.4406 - val_accuracy: 0.8157\n",
            "Epoch 297/500\n",
            "675/675 - 1s - loss: 0.4381 - accuracy: 0.8186 - val_loss: 0.4424 - val_accuracy: 0.8187\n",
            "Epoch 298/500\n",
            "675/675 - 1s - loss: 0.4365 - accuracy: 0.8192 - val_loss: 0.4440 - val_accuracy: 0.8183\n",
            "Epoch 299/500\n",
            "675/675 - 1s - loss: 0.4366 - accuracy: 0.8186 - val_loss: 0.4432 - val_accuracy: 0.8183\n",
            "Epoch 300/500\n",
            "675/675 - 1s - loss: 0.4397 - accuracy: 0.8176 - val_loss: 0.4421 - val_accuracy: 0.8154\n",
            "Epoch 301/500\n",
            "675/675 - 1s - loss: 0.4368 - accuracy: 0.8188 - val_loss: 0.4420 - val_accuracy: 0.8157\n",
            "Epoch 302/500\n",
            "675/675 - 1s - loss: 0.4364 - accuracy: 0.8192 - val_loss: 0.4412 - val_accuracy: 0.8161\n",
            "Epoch 303/500\n",
            "675/675 - 1s - loss: 0.4365 - accuracy: 0.8175 - val_loss: 0.4412 - val_accuracy: 0.8170\n",
            "Epoch 304/500\n",
            "675/675 - 1s - loss: 0.4368 - accuracy: 0.8187 - val_loss: 0.4439 - val_accuracy: 0.8174\n",
            "Epoch 305/500\n",
            "675/675 - 1s - loss: 0.4371 - accuracy: 0.8202 - val_loss: 0.4413 - val_accuracy: 0.8185\n",
            "Epoch 306/500\n",
            "675/675 - 1s - loss: 0.4370 - accuracy: 0.8194 - val_loss: 0.4418 - val_accuracy: 0.8159\n",
            "Epoch 307/500\n",
            "675/675 - 1s - loss: 0.4373 - accuracy: 0.8177 - val_loss: 0.4484 - val_accuracy: 0.8170\n",
            "Epoch 308/500\n",
            "675/675 - 1s - loss: 0.4364 - accuracy: 0.8189 - val_loss: 0.4409 - val_accuracy: 0.8170\n",
            "Epoch 309/500\n",
            "675/675 - 1s - loss: 0.4361 - accuracy: 0.8193 - val_loss: 0.4432 - val_accuracy: 0.8161\n",
            "Epoch 310/500\n",
            "675/675 - 1s - loss: 0.4367 - accuracy: 0.8190 - val_loss: 0.4458 - val_accuracy: 0.8183\n",
            "Epoch 311/500\n",
            "675/675 - 1s - loss: 0.4385 - accuracy: 0.8198 - val_loss: 0.4437 - val_accuracy: 0.8156\n",
            "Epoch 312/500\n",
            "675/675 - 1s - loss: 0.4367 - accuracy: 0.8187 - val_loss: 0.4469 - val_accuracy: 0.8172\n",
            "Epoch 313/500\n",
            "675/675 - 1s - loss: 0.4367 - accuracy: 0.8183 - val_loss: 0.4443 - val_accuracy: 0.8165\n",
            "Epoch 314/500\n",
            "675/675 - 1s - loss: 0.4367 - accuracy: 0.8179 - val_loss: 0.4435 - val_accuracy: 0.8172\n",
            "Epoch 315/500\n",
            "675/675 - 1s - loss: 0.4370 - accuracy: 0.8180 - val_loss: 0.4413 - val_accuracy: 0.8165\n",
            "Epoch 316/500\n",
            "675/675 - 1s - loss: 0.4360 - accuracy: 0.8187 - val_loss: 0.4513 - val_accuracy: 0.8156\n",
            "Epoch 317/500\n",
            "675/675 - 1s - loss: 0.4373 - accuracy: 0.8192 - val_loss: 0.4409 - val_accuracy: 0.8159\n",
            "Epoch 318/500\n",
            "675/675 - 1s - loss: 0.4364 - accuracy: 0.8184 - val_loss: 0.4441 - val_accuracy: 0.8165\n",
            "Epoch 319/500\n",
            "675/675 - 1s - loss: 0.4377 - accuracy: 0.8169 - val_loss: 0.4485 - val_accuracy: 0.8154\n",
            "Epoch 320/500\n",
            "675/675 - 1s - loss: 0.4364 - accuracy: 0.8189 - val_loss: 0.4444 - val_accuracy: 0.8174\n",
            "Epoch 321/500\n",
            "675/675 - 1s - loss: 0.4369 - accuracy: 0.8188 - val_loss: 0.4447 - val_accuracy: 0.8154\n",
            "Epoch 322/500\n",
            "675/675 - 1s - loss: 0.4367 - accuracy: 0.8188 - val_loss: 0.4447 - val_accuracy: 0.8176\n",
            "Epoch 323/500\n",
            "675/675 - 1s - loss: 0.4365 - accuracy: 0.8181 - val_loss: 0.4481 - val_accuracy: 0.8152\n",
            "Epoch 324/500\n",
            "675/675 - 1s - loss: 0.4362 - accuracy: 0.8185 - val_loss: 0.4451 - val_accuracy: 0.8187\n",
            "Epoch 325/500\n",
            "675/675 - 1s - loss: 0.4371 - accuracy: 0.8181 - val_loss: 0.4414 - val_accuracy: 0.8148\n",
            "Epoch 326/500\n",
            "675/675 - 1s - loss: 0.4374 - accuracy: 0.8191 - val_loss: 0.4430 - val_accuracy: 0.8167\n",
            "Epoch 327/500\n",
            "675/675 - 1s - loss: 0.4369 - accuracy: 0.8186 - val_loss: 0.4421 - val_accuracy: 0.8161\n",
            "Epoch 328/500\n",
            "675/675 - 1s - loss: 0.4356 - accuracy: 0.8188 - val_loss: 0.4469 - val_accuracy: 0.8159\n",
            "Epoch 329/500\n",
            "675/675 - 1s - loss: 0.4360 - accuracy: 0.8199 - val_loss: 0.4534 - val_accuracy: 0.8126\n",
            "Epoch 330/500\n",
            "675/675 - 1s - loss: 0.4365 - accuracy: 0.8178 - val_loss: 0.4426 - val_accuracy: 0.8181\n",
            "Epoch 331/500\n",
            "675/675 - 1s - loss: 0.4365 - accuracy: 0.8184 - val_loss: 0.4451 - val_accuracy: 0.8165\n",
            "Epoch 332/500\n",
            "675/675 - 1s - loss: 0.4363 - accuracy: 0.8176 - val_loss: 0.4411 - val_accuracy: 0.8174\n",
            "Epoch 333/500\n",
            "675/675 - 1s - loss: 0.4359 - accuracy: 0.8190 - val_loss: 0.4464 - val_accuracy: 0.8152\n",
            "Epoch 334/500\n",
            "675/675 - 1s - loss: 0.4367 - accuracy: 0.8188 - val_loss: 0.4433 - val_accuracy: 0.8156\n",
            "Epoch 335/500\n",
            "675/675 - 1s - loss: 0.4362 - accuracy: 0.8198 - val_loss: 0.4530 - val_accuracy: 0.8115\n",
            "Epoch 336/500\n",
            "675/675 - 1s - loss: 0.4365 - accuracy: 0.8182 - val_loss: 0.4446 - val_accuracy: 0.8150\n",
            "Epoch 337/500\n",
            "675/675 - 1s - loss: 0.4365 - accuracy: 0.8182 - val_loss: 0.4417 - val_accuracy: 0.8161\n",
            "Epoch 338/500\n",
            "675/675 - 1s - loss: 0.4372 - accuracy: 0.8194 - val_loss: 0.4407 - val_accuracy: 0.8152\n",
            "Epoch 339/500\n",
            "675/675 - 1s - loss: 0.4367 - accuracy: 0.8182 - val_loss: 0.4456 - val_accuracy: 0.8167\n",
            "Epoch 340/500\n",
            "675/675 - 1s - loss: 0.4370 - accuracy: 0.8187 - val_loss: 0.4471 - val_accuracy: 0.8150\n",
            "Epoch 341/500\n",
            "675/675 - 1s - loss: 0.4369 - accuracy: 0.8191 - val_loss: 0.4500 - val_accuracy: 0.8135\n",
            "Epoch 342/500\n",
            "675/675 - 1s - loss: 0.4362 - accuracy: 0.8183 - val_loss: 0.4448 - val_accuracy: 0.8169\n",
            "Epoch 343/500\n",
            "675/675 - 1s - loss: 0.4374 - accuracy: 0.8174 - val_loss: 0.4420 - val_accuracy: 0.8157\n",
            "Epoch 344/500\n",
            "675/675 - 1s - loss: 0.4366 - accuracy: 0.8201 - val_loss: 0.4431 - val_accuracy: 0.8167\n",
            "Epoch 345/500\n",
            "675/675 - 1s - loss: 0.4368 - accuracy: 0.8186 - val_loss: 0.4478 - val_accuracy: 0.8178\n",
            "Epoch 346/500\n",
            "675/675 - 1s - loss: 0.4369 - accuracy: 0.8188 - val_loss: 0.4424 - val_accuracy: 0.8178\n",
            "Epoch 347/500\n",
            "675/675 - 1s - loss: 0.4365 - accuracy: 0.8180 - val_loss: 0.4423 - val_accuracy: 0.8183\n",
            "Epoch 348/500\n",
            "675/675 - 1s - loss: 0.4378 - accuracy: 0.8188 - val_loss: 0.4430 - val_accuracy: 0.8163\n",
            "Epoch 349/500\n",
            "675/675 - 1s - loss: 0.4376 - accuracy: 0.8188 - val_loss: 0.4479 - val_accuracy: 0.8163\n",
            "Epoch 350/500\n",
            "675/675 - 1s - loss: 0.4367 - accuracy: 0.8183 - val_loss: 0.4416 - val_accuracy: 0.8161\n",
            "Epoch 351/500\n",
            "675/675 - 1s - loss: 0.4361 - accuracy: 0.8198 - val_loss: 0.4411 - val_accuracy: 0.8176\n",
            "Epoch 352/500\n",
            "675/675 - 1s - loss: 0.4369 - accuracy: 0.8188 - val_loss: 0.4400 - val_accuracy: 0.8165\n",
            "Epoch 353/500\n",
            "675/675 - 1s - loss: 0.4379 - accuracy: 0.8197 - val_loss: 0.4420 - val_accuracy: 0.8183\n",
            "Epoch 354/500\n",
            "675/675 - 1s - loss: 0.4370 - accuracy: 0.8183 - val_loss: 0.4484 - val_accuracy: 0.8172\n",
            "Epoch 355/500\n",
            "675/675 - 1s - loss: 0.4377 - accuracy: 0.8192 - val_loss: 0.4454 - val_accuracy: 0.8178\n",
            "Epoch 356/500\n",
            "675/675 - 1s - loss: 0.4369 - accuracy: 0.8174 - val_loss: 0.4420 - val_accuracy: 0.8181\n",
            "Epoch 357/500\n",
            "675/675 - 1s - loss: 0.4377 - accuracy: 0.8188 - val_loss: 0.4427 - val_accuracy: 0.8152\n",
            "Epoch 358/500\n",
            "675/675 - 1s - loss: 0.4370 - accuracy: 0.8193 - val_loss: 0.4468 - val_accuracy: 0.8161\n",
            "Epoch 359/500\n",
            "675/675 - 1s - loss: 0.4368 - accuracy: 0.8189 - val_loss: 0.4458 - val_accuracy: 0.8165\n",
            "Epoch 360/500\n",
            "675/675 - 1s - loss: 0.4371 - accuracy: 0.8189 - val_loss: 0.4435 - val_accuracy: 0.8180\n",
            "Epoch 361/500\n",
            "675/675 - 1s - loss: 0.4367 - accuracy: 0.8194 - val_loss: 0.4482 - val_accuracy: 0.8170\n",
            "Epoch 362/500\n",
            "675/675 - 1s - loss: 0.4364 - accuracy: 0.8190 - val_loss: 0.4419 - val_accuracy: 0.8144\n",
            "Epoch 363/500\n",
            "675/675 - 1s - loss: 0.4364 - accuracy: 0.8191 - val_loss: 0.4465 - val_accuracy: 0.8189\n",
            "Epoch 364/500\n",
            "675/675 - 1s - loss: 0.4361 - accuracy: 0.8183 - val_loss: 0.4411 - val_accuracy: 0.8178\n",
            "Epoch 365/500\n",
            "675/675 - 1s - loss: 0.4367 - accuracy: 0.8178 - val_loss: 0.4415 - val_accuracy: 0.8189\n",
            "Epoch 366/500\n",
            "675/675 - 1s - loss: 0.4363 - accuracy: 0.8180 - val_loss: 0.4492 - val_accuracy: 0.8148\n",
            "Epoch 367/500\n",
            "675/675 - 1s - loss: 0.4368 - accuracy: 0.8181 - val_loss: 0.4432 - val_accuracy: 0.8154\n",
            "Epoch 368/500\n",
            "675/675 - 1s - loss: 0.4374 - accuracy: 0.8200 - val_loss: 0.4441 - val_accuracy: 0.8185\n",
            "Epoch 369/500\n",
            "675/675 - 1s - loss: 0.4368 - accuracy: 0.8185 - val_loss: 0.4459 - val_accuracy: 0.8161\n",
            "Epoch 370/500\n",
            "675/675 - 1s - loss: 0.4371 - accuracy: 0.8186 - val_loss: 0.4424 - val_accuracy: 0.8176\n",
            "Epoch 371/500\n",
            "675/675 - 1s - loss: 0.4371 - accuracy: 0.8187 - val_loss: 0.4415 - val_accuracy: 0.8180\n",
            "Epoch 372/500\n",
            "675/675 - 1s - loss: 0.4370 - accuracy: 0.8188 - val_loss: 0.4415 - val_accuracy: 0.8167\n",
            "Epoch 373/500\n",
            "675/675 - 1s - loss: 0.4369 - accuracy: 0.8192 - val_loss: 0.4403 - val_accuracy: 0.8180\n",
            "Epoch 374/500\n",
            "675/675 - 1s - loss: 0.4384 - accuracy: 0.8196 - val_loss: 0.4402 - val_accuracy: 0.8176\n",
            "Epoch 375/500\n",
            "675/675 - 1s - loss: 0.4362 - accuracy: 0.8182 - val_loss: 0.4461 - val_accuracy: 0.8187\n",
            "Epoch 376/500\n",
            "675/675 - 1s - loss: 0.4377 - accuracy: 0.8187 - val_loss: 0.4458 - val_accuracy: 0.8174\n",
            "Epoch 377/500\n",
            "675/675 - 1s - loss: 0.4378 - accuracy: 0.8188 - val_loss: 0.4469 - val_accuracy: 0.8141\n",
            "Epoch 378/500\n",
            "675/675 - 1s - loss: 0.4373 - accuracy: 0.8188 - val_loss: 0.4445 - val_accuracy: 0.8167\n",
            "Epoch 379/500\n",
            "675/675 - 1s - loss: 0.4371 - accuracy: 0.8187 - val_loss: 0.4408 - val_accuracy: 0.8180\n",
            "Epoch 380/500\n",
            "675/675 - 1s - loss: 0.4372 - accuracy: 0.8179 - val_loss: 0.4407 - val_accuracy: 0.8163\n",
            "Epoch 381/500\n",
            "675/675 - 1s - loss: 0.4377 - accuracy: 0.8173 - val_loss: 0.4400 - val_accuracy: 0.8185\n",
            "Epoch 382/500\n",
            "675/675 - 1s - loss: 0.4374 - accuracy: 0.8195 - val_loss: 0.4392 - val_accuracy: 0.8154\n",
            "Epoch 383/500\n",
            "675/675 - 1s - loss: 0.4368 - accuracy: 0.8184 - val_loss: 0.4467 - val_accuracy: 0.8156\n",
            "Epoch 384/500\n",
            "675/675 - 1s - loss: 0.4367 - accuracy: 0.8184 - val_loss: 0.4421 - val_accuracy: 0.8150\n",
            "Epoch 385/500\n",
            "675/675 - 1s - loss: 0.4376 - accuracy: 0.8189 - val_loss: 0.4433 - val_accuracy: 0.8178\n",
            "Epoch 386/500\n",
            "675/675 - 1s - loss: 0.4365 - accuracy: 0.8187 - val_loss: 0.4421 - val_accuracy: 0.8180\n",
            "Epoch 387/500\n",
            "675/675 - 1s - loss: 0.4368 - accuracy: 0.8181 - val_loss: 0.4487 - val_accuracy: 0.8146\n",
            "Epoch 388/500\n",
            "675/675 - 1s - loss: 0.4374 - accuracy: 0.8170 - val_loss: 0.4423 - val_accuracy: 0.8185\n",
            "Epoch 389/500\n",
            "675/675 - 1s - loss: 0.4372 - accuracy: 0.8178 - val_loss: 0.4399 - val_accuracy: 0.8161\n",
            "Epoch 390/500\n",
            "675/675 - 1s - loss: 0.4367 - accuracy: 0.8191 - val_loss: 0.4461 - val_accuracy: 0.8170\n",
            "Epoch 391/500\n",
            "675/675 - 1s - loss: 0.4370 - accuracy: 0.8190 - val_loss: 0.4491 - val_accuracy: 0.8167\n",
            "Epoch 392/500\n",
            "675/675 - 1s - loss: 0.4372 - accuracy: 0.8183 - val_loss: 0.4430 - val_accuracy: 0.8193\n",
            "Epoch 393/500\n",
            "675/675 - 1s - loss: 0.4371 - accuracy: 0.8191 - val_loss: 0.4423 - val_accuracy: 0.8169\n",
            "Epoch 394/500\n",
            "675/675 - 1s - loss: 0.4368 - accuracy: 0.8186 - val_loss: 0.4442 - val_accuracy: 0.8156\n",
            "Epoch 395/500\n",
            "675/675 - 1s - loss: 0.4369 - accuracy: 0.8181 - val_loss: 0.4409 - val_accuracy: 0.8163\n",
            "Epoch 396/500\n",
            "675/675 - 1s - loss: 0.4364 - accuracy: 0.8179 - val_loss: 0.4407 - val_accuracy: 0.8176\n",
            "Epoch 397/500\n",
            "675/675 - 1s - loss: 0.4368 - accuracy: 0.8186 - val_loss: 0.4408 - val_accuracy: 0.8161\n",
            "Epoch 398/500\n",
            "675/675 - 1s - loss: 0.4364 - accuracy: 0.8194 - val_loss: 0.4472 - val_accuracy: 0.8169\n",
            "Epoch 399/500\n",
            "675/675 - 1s - loss: 0.4367 - accuracy: 0.8193 - val_loss: 0.4411 - val_accuracy: 0.8176\n",
            "Epoch 400/500\n",
            "675/675 - 1s - loss: 0.4366 - accuracy: 0.8193 - val_loss: 0.4467 - val_accuracy: 0.8165\n",
            "Epoch 401/500\n",
            "675/675 - 1s - loss: 0.4369 - accuracy: 0.8193 - val_loss: 0.4422 - val_accuracy: 0.8165\n",
            "Epoch 402/500\n",
            "675/675 - 1s - loss: 0.4370 - accuracy: 0.8190 - val_loss: 0.4413 - val_accuracy: 0.8176\n",
            "Epoch 403/500\n",
            "675/675 - 1s - loss: 0.4371 - accuracy: 0.8192 - val_loss: 0.4557 - val_accuracy: 0.8154\n",
            "Epoch 404/500\n",
            "675/675 - 1s - loss: 0.4375 - accuracy: 0.8195 - val_loss: 0.4422 - val_accuracy: 0.8174\n",
            "Epoch 405/500\n",
            "675/675 - 1s - loss: 0.4367 - accuracy: 0.8179 - val_loss: 0.4441 - val_accuracy: 0.8169\n",
            "Epoch 406/500\n",
            "675/675 - 1s - loss: 0.4376 - accuracy: 0.8190 - val_loss: 0.4450 - val_accuracy: 0.8163\n",
            "Epoch 407/500\n",
            "675/675 - 1s - loss: 0.4368 - accuracy: 0.8188 - val_loss: 0.4456 - val_accuracy: 0.8185\n",
            "Epoch 408/500\n",
            "675/675 - 1s - loss: 0.4356 - accuracy: 0.8189 - val_loss: 0.4517 - val_accuracy: 0.8161\n",
            "Epoch 409/500\n",
            "675/675 - 1s - loss: 0.4373 - accuracy: 0.8194 - val_loss: 0.4393 - val_accuracy: 0.8169\n",
            "Epoch 410/500\n",
            "675/675 - 1s - loss: 0.4378 - accuracy: 0.8182 - val_loss: 0.4395 - val_accuracy: 0.8193\n",
            "Epoch 411/500\n",
            "675/675 - 1s - loss: 0.4374 - accuracy: 0.8177 - val_loss: 0.4425 - val_accuracy: 0.8159\n",
            "Epoch 412/500\n",
            "675/675 - 1s - loss: 0.4366 - accuracy: 0.8182 - val_loss: 0.4454 - val_accuracy: 0.8165\n",
            "Epoch 413/500\n",
            "675/675 - 1s - loss: 0.4368 - accuracy: 0.8195 - val_loss: 0.4439 - val_accuracy: 0.8174\n",
            "Epoch 414/500\n",
            "675/675 - 1s - loss: 0.4377 - accuracy: 0.8190 - val_loss: 0.4440 - val_accuracy: 0.8172\n",
            "Epoch 415/500\n",
            "675/675 - 1s - loss: 0.4380 - accuracy: 0.8189 - val_loss: 0.4464 - val_accuracy: 0.8146\n",
            "Epoch 416/500\n",
            "675/675 - 1s - loss: 0.4365 - accuracy: 0.8190 - val_loss: 0.4444 - val_accuracy: 0.8163\n",
            "Epoch 417/500\n",
            "675/675 - 1s - loss: 0.4376 - accuracy: 0.8180 - val_loss: 0.4465 - val_accuracy: 0.8167\n",
            "Epoch 418/500\n",
            "675/675 - 1s - loss: 0.4376 - accuracy: 0.8191 - val_loss: 0.4403 - val_accuracy: 0.8156\n",
            "Epoch 419/500\n",
            "675/675 - 1s - loss: 0.4368 - accuracy: 0.8178 - val_loss: 0.4397 - val_accuracy: 0.8163\n",
            "Epoch 420/500\n",
            "675/675 - 1s - loss: 0.4362 - accuracy: 0.8187 - val_loss: 0.4435 - val_accuracy: 0.8172\n",
            "Epoch 421/500\n",
            "675/675 - 1s - loss: 0.4378 - accuracy: 0.8185 - val_loss: 0.4430 - val_accuracy: 0.8189\n",
            "Epoch 422/500\n",
            "675/675 - 1s - loss: 0.4368 - accuracy: 0.8181 - val_loss: 0.4390 - val_accuracy: 0.8178\n",
            "Epoch 423/500\n",
            "675/675 - 1s - loss: 0.4370 - accuracy: 0.8189 - val_loss: 0.4555 - val_accuracy: 0.8154\n",
            "Epoch 424/500\n",
            "675/675 - 1s - loss: 0.4363 - accuracy: 0.8195 - val_loss: 0.4478 - val_accuracy: 0.8159\n",
            "Epoch 425/500\n",
            "675/675 - 1s - loss: 0.4365 - accuracy: 0.8186 - val_loss: 0.4423 - val_accuracy: 0.8180\n",
            "Epoch 426/500\n",
            "675/675 - 1s - loss: 0.4371 - accuracy: 0.8186 - val_loss: 0.4409 - val_accuracy: 0.8165\n",
            "Epoch 427/500\n",
            "675/675 - 1s - loss: 0.4370 - accuracy: 0.8194 - val_loss: 0.4418 - val_accuracy: 0.8165\n",
            "Epoch 428/500\n",
            "675/675 - 1s - loss: 0.4366 - accuracy: 0.8186 - val_loss: 0.4424 - val_accuracy: 0.8170\n",
            "Epoch 429/500\n",
            "675/675 - 1s - loss: 0.4370 - accuracy: 0.8191 - val_loss: 0.4420 - val_accuracy: 0.8159\n",
            "Epoch 430/500\n",
            "675/675 - 1s - loss: 0.4365 - accuracy: 0.8194 - val_loss: 0.4410 - val_accuracy: 0.8180\n",
            "Epoch 431/500\n",
            "675/675 - 1s - loss: 0.4359 - accuracy: 0.8190 - val_loss: 0.4451 - val_accuracy: 0.8176\n",
            "Epoch 432/500\n",
            "675/675 - 1s - loss: 0.4361 - accuracy: 0.8191 - val_loss: 0.4420 - val_accuracy: 0.8167\n",
            "Epoch 433/500\n",
            "675/675 - 1s - loss: 0.4376 - accuracy: 0.8183 - val_loss: 0.4406 - val_accuracy: 0.8150\n",
            "Epoch 434/500\n",
            "675/675 - 1s - loss: 0.4394 - accuracy: 0.8191 - val_loss: 0.4388 - val_accuracy: 0.8161\n",
            "Epoch 435/500\n",
            "675/675 - 1s - loss: 0.4377 - accuracy: 0.8175 - val_loss: 0.4406 - val_accuracy: 0.8159\n",
            "Epoch 436/500\n",
            "675/675 - 1s - loss: 0.4363 - accuracy: 0.8190 - val_loss: 0.4399 - val_accuracy: 0.8181\n",
            "Epoch 437/500\n",
            "675/675 - 1s - loss: 0.4364 - accuracy: 0.8185 - val_loss: 0.4478 - val_accuracy: 0.8189\n",
            "Epoch 438/500\n",
            "675/675 - 1s - loss: 0.4376 - accuracy: 0.8186 - val_loss: 0.4421 - val_accuracy: 0.8181\n",
            "Epoch 439/500\n",
            "675/675 - 1s - loss: 0.4362 - accuracy: 0.8186 - val_loss: 0.4547 - val_accuracy: 0.8161\n",
            "Epoch 440/500\n",
            "675/675 - 1s - loss: 0.4372 - accuracy: 0.8186 - val_loss: 0.4577 - val_accuracy: 0.8154\n",
            "Epoch 441/500\n",
            "675/675 - 1s - loss: 0.4376 - accuracy: 0.8190 - val_loss: 0.4431 - val_accuracy: 0.8170\n",
            "Epoch 442/500\n",
            "675/675 - 1s - loss: 0.4373 - accuracy: 0.8190 - val_loss: 0.4428 - val_accuracy: 0.8185\n",
            "Epoch 443/500\n",
            "675/675 - 1s - loss: 0.4367 - accuracy: 0.8189 - val_loss: 0.4500 - val_accuracy: 0.8169\n",
            "Epoch 444/500\n",
            "675/675 - 1s - loss: 0.4366 - accuracy: 0.8195 - val_loss: 0.4456 - val_accuracy: 0.8174\n",
            "Epoch 445/500\n",
            "675/675 - 1s - loss: 0.4369 - accuracy: 0.8186 - val_loss: 0.4403 - val_accuracy: 0.8159\n",
            "Epoch 446/500\n",
            "675/675 - 1s - loss: 0.4366 - accuracy: 0.8185 - val_loss: 0.4472 - val_accuracy: 0.8174\n",
            "Epoch 447/500\n",
            "675/675 - 1s - loss: 0.4364 - accuracy: 0.8200 - val_loss: 0.4438 - val_accuracy: 0.8176\n",
            "Epoch 448/500\n",
            "675/675 - 1s - loss: 0.4370 - accuracy: 0.8201 - val_loss: 0.4429 - val_accuracy: 0.8165\n",
            "Epoch 449/500\n",
            "675/675 - 1s - loss: 0.4367 - accuracy: 0.8186 - val_loss: 0.4382 - val_accuracy: 0.8178\n",
            "Epoch 450/500\n",
            "675/675 - 1s - loss: 0.4376 - accuracy: 0.8193 - val_loss: 0.4407 - val_accuracy: 0.8178\n",
            "Epoch 451/500\n",
            "675/675 - 1s - loss: 0.4363 - accuracy: 0.8199 - val_loss: 0.4425 - val_accuracy: 0.8181\n",
            "Epoch 452/500\n",
            "675/675 - 1s - loss: 0.4363 - accuracy: 0.8187 - val_loss: 0.4420 - val_accuracy: 0.8185\n",
            "Epoch 453/500\n",
            "675/675 - 1s - loss: 0.4366 - accuracy: 0.8185 - val_loss: 0.4410 - val_accuracy: 0.8170\n",
            "Epoch 454/500\n",
            "675/675 - 1s - loss: 0.4378 - accuracy: 0.8201 - val_loss: 0.4433 - val_accuracy: 0.8165\n",
            "Epoch 455/500\n",
            "675/675 - 1s - loss: 0.4378 - accuracy: 0.8196 - val_loss: 0.4403 - val_accuracy: 0.8157\n",
            "Epoch 456/500\n",
            "675/675 - 1s - loss: 0.4359 - accuracy: 0.8202 - val_loss: 0.4468 - val_accuracy: 0.8161\n",
            "Epoch 457/500\n",
            "675/675 - 1s - loss: 0.4364 - accuracy: 0.8186 - val_loss: 0.4389 - val_accuracy: 0.8170\n",
            "Epoch 458/500\n",
            "675/675 - 1s - loss: 0.4365 - accuracy: 0.8191 - val_loss: 0.4392 - val_accuracy: 0.8180\n",
            "Epoch 459/500\n",
            "675/675 - 1s - loss: 0.4381 - accuracy: 0.8189 - val_loss: 0.4401 - val_accuracy: 0.8165\n",
            "Epoch 460/500\n",
            "675/675 - 1s - loss: 0.4362 - accuracy: 0.8185 - val_loss: 0.4412 - val_accuracy: 0.8178\n",
            "Epoch 461/500\n",
            "675/675 - 1s - loss: 0.4362 - accuracy: 0.8185 - val_loss: 0.4412 - val_accuracy: 0.8191\n",
            "Epoch 462/500\n",
            "675/675 - 1s - loss: 0.4359 - accuracy: 0.8177 - val_loss: 0.4418 - val_accuracy: 0.8165\n",
            "Epoch 463/500\n",
            "675/675 - 1s - loss: 0.4362 - accuracy: 0.8190 - val_loss: 0.4396 - val_accuracy: 0.8181\n",
            "Epoch 464/500\n",
            "675/675 - 1s - loss: 0.4370 - accuracy: 0.8181 - val_loss: 0.4425 - val_accuracy: 0.8181\n",
            "Epoch 465/500\n",
            "675/675 - 1s - loss: 0.4365 - accuracy: 0.8185 - val_loss: 0.4405 - val_accuracy: 0.8163\n",
            "Epoch 466/500\n",
            "675/675 - 1s - loss: 0.4372 - accuracy: 0.8190 - val_loss: 0.4424 - val_accuracy: 0.8180\n",
            "Epoch 467/500\n",
            "675/675 - 1s - loss: 0.4383 - accuracy: 0.8178 - val_loss: 0.4422 - val_accuracy: 0.8185\n",
            "Epoch 468/500\n",
            "675/675 - 1s - loss: 0.4374 - accuracy: 0.8180 - val_loss: 0.4412 - val_accuracy: 0.8157\n",
            "Epoch 469/500\n",
            "675/675 - 1s - loss: 0.4387 - accuracy: 0.8180 - val_loss: 0.4524 - val_accuracy: 0.8167\n",
            "Epoch 470/500\n",
            "675/675 - 1s - loss: 0.4365 - accuracy: 0.8184 - val_loss: 0.4379 - val_accuracy: 0.8157\n",
            "Epoch 471/500\n",
            "675/675 - 1s - loss: 0.4369 - accuracy: 0.8200 - val_loss: 0.4466 - val_accuracy: 0.8161\n",
            "Epoch 472/500\n",
            "675/675 - 1s - loss: 0.4365 - accuracy: 0.8189 - val_loss: 0.4429 - val_accuracy: 0.8159\n",
            "Epoch 473/500\n",
            "675/675 - 1s - loss: 0.4363 - accuracy: 0.8182 - val_loss: 0.4544 - val_accuracy: 0.8178\n",
            "Epoch 474/500\n",
            "675/675 - 1s - loss: 0.4374 - accuracy: 0.8193 - val_loss: 0.4401 - val_accuracy: 0.8165\n",
            "Epoch 475/500\n",
            "675/675 - 1s - loss: 0.4369 - accuracy: 0.8188 - val_loss: 0.4539 - val_accuracy: 0.8176\n",
            "Epoch 476/500\n",
            "675/675 - 1s - loss: 0.4362 - accuracy: 0.8181 - val_loss: 0.4416 - val_accuracy: 0.8161\n",
            "Epoch 477/500\n",
            "675/675 - 1s - loss: 0.4359 - accuracy: 0.8188 - val_loss: 0.4400 - val_accuracy: 0.8183\n",
            "Epoch 478/500\n",
            "675/675 - 1s - loss: 0.4359 - accuracy: 0.8200 - val_loss: 0.4402 - val_accuracy: 0.8148\n",
            "Epoch 479/500\n",
            "675/675 - 1s - loss: 0.4362 - accuracy: 0.8177 - val_loss: 0.4430 - val_accuracy: 0.8185\n",
            "Epoch 480/500\n",
            "675/675 - 1s - loss: 0.4368 - accuracy: 0.8193 - val_loss: 0.4450 - val_accuracy: 0.8157\n",
            "Epoch 481/500\n",
            "675/675 - 1s - loss: 0.4363 - accuracy: 0.8199 - val_loss: 0.4422 - val_accuracy: 0.8169\n",
            "Epoch 482/500\n",
            "675/675 - 1s - loss: 0.4374 - accuracy: 0.8198 - val_loss: 0.4413 - val_accuracy: 0.8172\n",
            "Epoch 483/500\n",
            "675/675 - 1s - loss: 0.4362 - accuracy: 0.8184 - val_loss: 0.4462 - val_accuracy: 0.8189\n",
            "Epoch 484/500\n",
            "675/675 - 1s - loss: 0.4357 - accuracy: 0.8190 - val_loss: 0.4418 - val_accuracy: 0.8152\n",
            "Epoch 485/500\n",
            "675/675 - 1s - loss: 0.4364 - accuracy: 0.8186 - val_loss: 0.4433 - val_accuracy: 0.8167\n",
            "Epoch 486/500\n",
            "675/675 - 1s - loss: 0.4373 - accuracy: 0.8188 - val_loss: 0.4442 - val_accuracy: 0.8169\n",
            "Epoch 487/500\n",
            "675/675 - 1s - loss: 0.4369 - accuracy: 0.8184 - val_loss: 0.4386 - val_accuracy: 0.8185\n",
            "Epoch 488/500\n",
            "675/675 - 1s - loss: 0.4366 - accuracy: 0.8192 - val_loss: 0.4417 - val_accuracy: 0.8161\n",
            "Epoch 489/500\n",
            "675/675 - 1s - loss: 0.4365 - accuracy: 0.8194 - val_loss: 0.4478 - val_accuracy: 0.8176\n",
            "Epoch 490/500\n",
            "675/675 - 1s - loss: 0.4369 - accuracy: 0.8193 - val_loss: 0.4380 - val_accuracy: 0.8169\n",
            "Epoch 491/500\n",
            "675/675 - 1s - loss: 0.4362 - accuracy: 0.8207 - val_loss: 0.4407 - val_accuracy: 0.8176\n",
            "Epoch 492/500\n",
            "675/675 - 1s - loss: 0.4361 - accuracy: 0.8199 - val_loss: 0.4505 - val_accuracy: 0.8172\n",
            "Epoch 493/500\n",
            "675/675 - 1s - loss: 0.4358 - accuracy: 0.8196 - val_loss: 0.4391 - val_accuracy: 0.8163\n",
            "Epoch 494/500\n",
            "675/675 - 1s - loss: 0.4364 - accuracy: 0.8181 - val_loss: 0.4423 - val_accuracy: 0.8159\n",
            "Epoch 495/500\n",
            "675/675 - 1s - loss: 0.4361 - accuracy: 0.8195 - val_loss: 0.4489 - val_accuracy: 0.8174\n",
            "Epoch 496/500\n",
            "675/675 - 1s - loss: 0.4361 - accuracy: 0.8189 - val_loss: 0.4460 - val_accuracy: 0.8180\n",
            "Epoch 497/500\n",
            "675/675 - 1s - loss: 0.4368 - accuracy: 0.8177 - val_loss: 0.4437 - val_accuracy: 0.8193\n",
            "Epoch 498/500\n",
            "675/675 - 1s - loss: 0.4366 - accuracy: 0.8183 - val_loss: 0.4441 - val_accuracy: 0.8156\n",
            "Epoch 499/500\n",
            "675/675 - 1s - loss: 0.4361 - accuracy: 0.8186 - val_loss: 0.4440 - val_accuracy: 0.8156\n",
            "Epoch 500/500\n",
            "675/675 - 1s - loss: 0.4365 - accuracy: 0.8201 - val_loss: 0.4463 - val_accuracy: 0.8176\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hmXaxRPqhG-H"
      },
      "source": [
        "test_data = pd.read_csv(io.BytesIO(uploaded['test.csv']))"
      ],
      "execution_count": 137,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kHlvrMGjh5lG"
      },
      "source": [
        "scaled_test_data = minmax_scaling(test_data,columns=['ID','LIMIT_BAL',\r\n",
        "'SEX',\r\n",
        "'EDUCATION',\r\n",
        "'MARRIAGE',\r\n",
        "'AGE',\r\n",
        "'PAY_0',\r\n",
        "'PAY_2',\r\n",
        "'PAY_3',\r\n",
        "'PAY_4',\r\n",
        "'PAY_5',\r\n",
        "'PAY_6',\r\n",
        "'BILL_AMT1',\r\n",
        "'BILL_AMT2',\r\n",
        "'BILL_AMT3',\r\n",
        "'BILL_AMT4',\r\n",
        "'BILL_AMT5',\r\n",
        "'BILL_AMT6',\r\n",
        "'PAY_AMT1',\r\n",
        "'PAY_AMT2',\r\n",
        "'PAY_AMT3',\r\n",
        "'PAY_AMT4','PAY_AMT5','PAY_AMT6'])"
      ],
      "execution_count": 138,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9vPYoB0qiQql"
      },
      "source": [
        "y_hat = model.predict(scaled_test_data)\r\n",
        "test_id = test_data['ID']"
      ],
      "execution_count": 139,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xo8ZKsWkjhhg"
      },
      "source": [
        "y_hat = [0 if i<=0.5 else 1 for i in y_hat]\r\n",
        "temp_tuples = list(zip(test_id,y_hat))\r\n",
        "df = pd.DataFrame(temp_tuples, columns=['ID','default payment next month'])"
      ],
      "execution_count": 143,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "id": "kPzVQi8ZkFiU",
        "outputId": "0c2a04e6-24fb-4533-fec2-f38f44c9945a"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": 144,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ID</th>\n",
              "      <th>default payment next month</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>12826</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>7700</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1976</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>16714</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2146</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      ID  default payment next month\n",
              "0  12826                           0\n",
              "1   7700                           0\n",
              "2   1976                           0\n",
              "3  16714                           1\n",
              "4   2146                           0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 144
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wmA4CTz6lU0g"
      },
      "source": [
        "df.to_csv('output.csv')"
      ],
      "execution_count": 145,
      "outputs": []
    }
  ]
}